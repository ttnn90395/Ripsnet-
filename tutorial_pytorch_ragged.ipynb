{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d710fbb9",
      "metadata": {
        "id": "d710fbb9"
      },
      "source": [
        "In this tutorial, we show how to use RipsNet to learn the topology of very simple synthetic data sets comprised of (noisy) circles. Let's first define the seed (for reproducibility), the number of point clouds that we will use for training RipsNet, the number of point clouds we will use to test it, the cardinality of the point clouds and finally the amount of corrupted points (when noise is added)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "40bc920c",
      "metadata": {
        "id": "40bc920c"
      },
      "outputs": [],
      "source": [
        "N_sets_train = 1800  # Number of train point clouds\n",
        "N_sets_test  = 300  # Number of test  point clouds\n",
        "N_points     = 600  # Point cloud cardinality\n",
        "N_noise      = 200  # Number of corrupted points"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b65ee958",
      "metadata": {
        "id": "b65ee958"
      },
      "source": [
        "### Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ec5333fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec5333fc",
        "outputId": "19c23a05-2671-43fc-ed67-94efa95bbcb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: pip: command not found\n"
          ]
        }
      ],
      "source": [
        "!pip install gudhi tqdm matplotlib scikit-learn scipy torch xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e3c856f8",
      "metadata": {
        "id": "e3c856f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "e5b9015a-b96e-46c7-ea9e-4312ddcd4d6e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gudhi'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-817805896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgudhi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgudhi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiagramSelector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLandscape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPersistenceImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gudhi'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import gudhi as gd\n",
        "from gudhi.representations import DiagramSelector, Landscape, PersistenceImage\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.optim import Adamax\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###utils\n"
      ],
      "metadata": {
        "id": "X8b1XULH3At5"
      },
      "id": "X8b1XULH3At5"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adamax\n",
        "\n",
        "class DenseRagged(nn.Module):\n",
        "    def __init__(self, in_features=None, out_features=30, activation='relu', use_bias=True):\n",
        "        super(DenseRagged, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.use_bias = use_bias\n",
        "        self.activation = activation\n",
        "\n",
        "        self.weight = None\n",
        "        self.bias = None\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = []\n",
        "        for x in inputs:\n",
        "            if self.weight is None:\n",
        "                in_features = x.shape[-1]\n",
        "                self.weight = nn.Parameter(torch.randn(in_features, self.out_features) * 0.01)\n",
        "                if self.use_bias:\n",
        "                    self.bias = nn.Parameter(torch.zeros(self.out_features))\n",
        "            y = torch.matmul(x, self.weight)\n",
        "            if self.use_bias:\n",
        "                y = y + self.bias\n",
        "            if self.activation == 'relu':\n",
        "                y = F.relu(y)\n",
        "            elif self.activation == 'sigmoid':\n",
        "                y = torch.sigmoid(y)\n",
        "            elif self.activation == 'tanh':\n",
        "                y = torch.tanh(y)\n",
        "            outputs.append(y)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "class PermopRagged(nn.Module):\n",
        "    def forward(self, inputs):\n",
        "        return torch.stack([torch.sum(x, dim=0) for x in inputs])\n",
        "\n",
        "\n",
        "class RaggedPersistenceModel(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super(RaggedPersistenceModel, self).__init__()\n",
        "        self.ragged_layers = nn.ModuleList([\n",
        "            DenseRagged(out_features=30, activation='relu'),\n",
        "            DenseRagged(out_features=20, activation='relu'),\n",
        "            DenseRagged(out_features=10, activation='relu')\n",
        "        ])\n",
        "        self.perm = PermopRagged()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(10, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 200),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(200, output_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.ragged_layers:\n",
        "            x = layer(x)\n",
        "        x = self.perm(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gudhi as gd\n",
        "\n",
        "\n",
        "####################################\n",
        "###  Creation of point clouds    ###\n",
        "####################################\n",
        "\n",
        "def create_circle(N_points, r, x_0, y_0):\n",
        "    X = []\n",
        "    for i in range(N_points):\n",
        "        theta = np.random.uniform() * 2 * np.pi\n",
        "        X.append([(r * np.cos(theta)) + x_0, (r * np.sin(theta) + y_0)])\n",
        "    return np.array(X)\n",
        "\n",
        "\n",
        "def create_1_circle_clean(N_points):\n",
        "    r = 2\n",
        "    x_0, y_0 = 10 * np.random.rand() - 5, 10 * np.random.rand() - 5\n",
        "    return create_circle(N_points, r, x_0, y_0)\n",
        "\n",
        "\n",
        "def create_2_circle_clean(N_points):\n",
        "    r1 = 5\n",
        "    r2 = 3\n",
        "    x_0, y_0 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    x_1, y_1 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    while np.sqrt((x_0 - x_1) ** 2 + (y_0 - y_1) ** 2) <= r1 + r2:\n",
        "        x_1, y_1 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    circle1 = create_circle(N_points // 2, r1, x_0, y_0)\n",
        "    circle2 = create_circle(N_points - N_points // 2, r2, x_1, y_1)\n",
        "    X = [0] * N_points\n",
        "    X[:N_points // 2] = circle1\n",
        "    X[N_points // 2:] = circle2\n",
        "    np.random.shuffle(X)\n",
        "    return np.array(X)\n",
        "\n",
        "\n",
        "def create_3_circle_clean(N_points):\n",
        "    r0 = 5\n",
        "    r1 = 3\n",
        "    r2 = 2\n",
        "    x_0, y_0 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    x_1, y_1 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    while np.sqrt((x_0 - x_1) ** 2 + (y_0 - y_1) ** 2) <= r0 + r1:\n",
        "        x_1, y_1 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "\n",
        "    x_2, y_2 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    while(np.sqrt((x_0 - x_2)**2 + (y_0 - y_2)**2) <= r0 + r2) or (np.sqrt((x_1 - x_2)**2 + (y_1 - y_2)**2) <= r1 + r2):\n",
        "        x_2, y_2 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "\n",
        "    circle0 = create_circle(N_points // 3, r0, x_0, y_0)\n",
        "    circle1 = create_circle(N_points // 3, r1, x_1, y_1)\n",
        "    circle2 = create_circle(N_points // 3, r2, x_2, y_2)\n",
        "\n",
        "    # Handler in case N_points mod 3 != 0.\n",
        "    true_N_points = 3 * (N_points // 3)\n",
        "\n",
        "    X = [[0,0]] * true_N_points\n",
        "    X[:true_N_points // 3] = circle0\n",
        "    X[true_N_points // 3:2 * true_N_points // 3] = circle1\n",
        "    X[2 * true_N_points // 3:] = circle2\n",
        "    np.random.shuffle(X)\n",
        "    return np.array(X)\n",
        "\n",
        "\n",
        "def create_1_circle_noisy(N_points, N_noise):\n",
        "    r = 2\n",
        "    x_0, y_0 = 10 * np.random.rand() - 5, 10 * np.random.rand() - 5\n",
        "    X = create_circle(N_points, r, x_0, y_0)\n",
        "    noise = []\n",
        "    for i in range(N_noise):\n",
        "        noise.append([np.random.uniform(x_0 - r, x_0 + r),\n",
        "                      np.random.uniform(y_0 - r, y_0 + r)])\n",
        "    X = np.array(X)\n",
        "    X[np.random.choice(np.arange(len(X)), size=N_noise, replace=False, p=None)] = np.array(noise)\n",
        "    return X\n",
        "\n",
        "\n",
        "def create_2_circle_noisy(N_points, N_noise):\n",
        "    r1 = 5\n",
        "    r2 = 3\n",
        "    x_0, y_0 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    x_1, y_1 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    while(np.sqrt((x_0 - x_1)**2 + (y_0 - y_1)**2) <= r1 + r2):\n",
        "        x_1, y_1 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    circle1 = create_circle(N_points // 2, r1, x_0, y_0)\n",
        "    circle2 = create_circle(N_points - N_points // 2, r2, x_1, y_1)\n",
        "    X = [0] * N_points\n",
        "    X[:N_points // 2] = circle1\n",
        "    X[N_points // 2:] = circle2\n",
        "    np.random.shuffle(X)\n",
        "    noise = []\n",
        "    for i in range(N_noise):\n",
        "        noise.append([np.random.uniform(min(x_0 - r1, x_1 - r2), max(x_0 + r1, x_1 + r2)),\n",
        "                      np.random.uniform(min(y_0 - r1, y_1 - r2), max(y_0 + r1, y_1 + r2))])\n",
        "    X = np.array(X)\n",
        "    X[np.random.choice(np.arange(len(X)), size=N_noise, replace=False, p=None)] = np.array(noise)\n",
        "    return X\n",
        "\n",
        "\n",
        "def create_3_circle_noisy(N_points, N_noise):\n",
        "    r0 = 5\n",
        "    r1 = 3\n",
        "    r2 = 2\n",
        "    x_0, y_0 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    x_1, y_1 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    while np.sqrt((x_0 - x_1) ** 2 + (y_0 - y_1) ** 2) <= r0 + r1:\n",
        "        x_1, y_1 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    x_2, y_2 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    while(np.sqrt((x_0 - x_2)**2 + (y_0 - y_2)**2) <= r0 + r2) or (np.sqrt((x_1 - x_2)**2 + (y_1 - y_2)**2) <= r1 + r2):\n",
        "        x_2, y_2 = 30 * np.random.rand() - 15, 30 * np.random.rand() - 15\n",
        "    circle0 = create_circle(N_points // 3, r0, x_0, y_0)\n",
        "    circle1 = create_circle(N_points // 3, r1, x_1, y_1)\n",
        "    circle2 = create_circle(N_points // 3, r2, x_2, y_2)\n",
        "\n",
        "    true_N_points = 3 * (N_points // 3)\n",
        "    X = [[0,0]] * true_N_points\n",
        "    X[:true_N_points // 3] = circle0\n",
        "    X[true_N_points // 3:2 * true_N_points // 3] = circle1\n",
        "    X[2 * true_N_points // 3:] = circle2\n",
        "\n",
        "    np.random.shuffle(X)\n",
        "    noise = []\n",
        "    for i in range(N_noise):\n",
        "        noise.append([np.random.uniform(np.min([x_0 - r0, x_1 - r1, x_2 - r2]), np.max([x_0 + r0, x_1 + r1, x_2 + r2])),\n",
        "                      np.random.uniform(np.min([y_0 - r0, y_1 - r1, y_2 - r2]), np.max([y_0 + r0, y_1 + r1, y_2 + r2]))])\n",
        "    X = np.array(X)\n",
        "    X[np.random.choice(np.arange(len(X)), size=N_noise, replace=False, p=None)] = np.array(noise)\n",
        "    return X\n",
        "\n",
        "def augment_isometries(pc, n, rng, trans_frac=0.08):\n",
        "    bbox = pc.max(axis=0) - pc.min(axis=0)\n",
        "    t_max = trans_frac * np.linalg.norm(bbox)  # translation scale relative to cloud size\n",
        "    augmented = []\n",
        "    for _ in range(n):\n",
        "        theta = rng.uniform(0, 2 * np.pi)\n",
        "        R = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
        "        t = rng.uniform(-t_max, t_max, size=2)\n",
        "        augmented.append((pc @ R.T) + t)\n",
        "    return augmented\n",
        "\n",
        "def data_augmentation_by_isometries(data_train, label_train, n_augment_per_sample, seed=42):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    aug_data, aug_labels = [], []\n",
        "    for pc, lbl in zip(data_train, label_train):\n",
        "        aug_data.append(pc)\n",
        "        aug_labels.append(lbl)\n",
        "        for pc_aug in augment_isometries(pc, n_augment_per_sample, rng):\n",
        "            aug_data.append(pc_aug)\n",
        "            aug_labels.append(lbl)\n",
        "    return aug_data, aug_labels\n",
        "\n",
        "def create_multiple_circles(N_sets_train, N_points, noisy=False, N_noise=0, n_augment_per_sample = 0):\n",
        "\n",
        "    data_train, PD_train = [[] for _ in range(N_sets_train)], []\n",
        "    label_train = np.zeros((N_sets_train,))\n",
        "\n",
        "    if not noisy:\n",
        "        for i in tqdm(range(N_sets_train // 3)):\n",
        "            data_train[i] = create_1_circle_clean(N_points)\n",
        "            label_train[i] = 1\n",
        "        for i in tqdm(range(N_sets_train // 3, 2 * N_sets_train // 3)):\n",
        "            data_train[i] = create_2_circle_clean(N_points)\n",
        "            label_train[i] = 2\n",
        "        for i in tqdm(range(2 * N_sets_train // 3, N_sets_train)):\n",
        "            data_train[i] = create_3_circle_clean(N_points)\n",
        "            label_train[i] = 3\n",
        "    else:\n",
        "        for i in tqdm(range(N_sets_train // 3)):\n",
        "            data_train[i] = create_1_circle_noisy(N_points, N_noise)\n",
        "            label_train[i] = 1\n",
        "        for i in tqdm(range(N_sets_train // 3, 2 * N_sets_train // 3)):\n",
        "            data_train[i] = create_2_circle_noisy(N_points, N_noise)\n",
        "            label_train[i] = 2\n",
        "        for i in tqdm(range(2 * N_sets_train // 3, N_sets_train)):\n",
        "            data_train[i] = create_3_circle_noisy(N_points, N_noise)\n",
        "            label_train[i] = 3\n",
        "\n",
        "    shuffler = np.random.permutation(len(data_train))\n",
        "    label_train = label_train[shuffler]\n",
        "    data_train = [data_train[p] for p in shuffler]\n",
        "    if (n_augment_per_sample > 0):\n",
        "        data_train,label_train = data_augmentation_by_isometries(data_train, label_train, n_augment_per_sample, seed=42)\n",
        "    return data_train, label_train\n",
        "\n",
        "\n",
        "############################################\n",
        "### Computation of persistence diagrams  ###\n",
        "############################################\n",
        "\n",
        "\n",
        "def compute_PD(dataset, i):\n",
        "    u = np.array(dataset[i])\n",
        "    rcX = gd.AlphaComplex(points=u).create_simplex_tree()\n",
        "    rcX.persistence()\n",
        "    dgm = rcX.persistence_intervals_in_dimension(1)\n",
        "    return dgm"
      ],
      "metadata": {
        "id": "xGSfiEQo3DyH"
      },
      "id": "xGSfiEQo3DyH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ffa4e5ea",
      "metadata": {
        "id": "ffa4e5ea"
      },
      "source": [
        "### Definition of our Train/Test sets\n",
        "Next we use helper functions to compute these point clouds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f615886",
      "metadata": {
        "id": "4f615886"
      },
      "outputs": [],
      "source": [
        "data_train,      label_train       = create_multiple_circles(N_sets_train, N_points, noisy=0, N_noise=N_noise, n_augment_per_sample= 4)\n",
        "clean_data_test, clean_label_test  = create_multiple_circles(N_sets_test,  N_points, noisy=0, N_noise=N_noise,)\n",
        "noisy_data_test, noisy_label_test  = create_multiple_circles(N_sets_test,  N_points, noisy=1, N_noise=N_noise)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a73e5a2",
      "metadata": {
        "id": "2a73e5a2"
      },
      "source": [
        "Let's check some of these point clouds!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5595a4d0",
      "metadata": {
        "id": "5595a4d0"
      },
      "source": [
        "#### Plotting Point Clouds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09541458",
      "metadata": {
        "id": "09541458"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(3, 3, width_ratios=[1,1,1], wspace=0.0, hspace=0.0)\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        ax = plt.subplot(gs[i,j])\n",
        "        ax.scatter(clean_data_test[3*i+j][:,0], clean_data_test[3*i+j][:,1], s=3)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "plt.savefig('clean_gudhi_pc.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5da51de",
      "metadata": {
        "id": "e5da51de"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(3, 3, width_ratios=[1,1,1], wspace=0.0, hspace=0.0)\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        ax = plt.subplot(gs[i,j])\n",
        "        ax.scatter(noisy_data_test[3*i+j][:,0], noisy_data_test[3*i+j][:,1], s=3)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "plt.savefig('noisy_gudhi_pc.png', bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f0cf0e5",
      "metadata": {
        "id": "5f0cf0e5"
      },
      "source": [
        "#### Cleaning Labels\n",
        "As one can see, they contain 1 to 3 circular shapes. We will use these circle numbers later for checking the accuracy of the topology computed by RipsNet. For now, let's save them as proper labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3acd752",
      "metadata": {
        "id": "b3acd752"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder().fit(label_train)\n",
        "label_classif_train = le.transform(label_train)\n",
        "clean_label_classif_test  = le.transform(clean_label_test)\n",
        "noisy_label_classif_test  = le.transform(noisy_label_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9972a77d",
      "metadata": {
        "id": "9972a77d"
      },
      "source": [
        "#### Distance Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5309ee3e",
      "metadata": {
        "id": "5309ee3e"
      },
      "outputs": [],
      "source": [
        "def distance_matrix(point_cloud):\n",
        "    \"\"\"\n",
        "    Compute pairwise Euclidean distance matrix for a point cloud.\n",
        "    Accepts numpy array, list-of-lists, or torch.Tensor of shape (N, d).\n",
        "    Returns a numpy array of shape (N, N).\n",
        "    \"\"\"\n",
        "    # rely on existing imports: np, torch\n",
        "    if isinstance(point_cloud, __import__(\"torch\").Tensor):\n",
        "        point_cloud = point_cloud.cpu().numpy()\n",
        "    pc = np.asarray(point_cloud, dtype=float)\n",
        "    if pc.ndim == 1:\n",
        "        pc = pc.reshape(-1, 1)\n",
        "    diff = pc[:, None, :] - pc[None, :, :]\n",
        "    return np.sqrt((diff ** 2).sum(axis=-1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "976b8864",
      "metadata": {
        "id": "976b8864"
      },
      "source": [
        "### Topology of point clouds"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ee077f6",
      "metadata": {
        "id": "4ee077f6"
      },
      "source": [
        "In order to train RipsNet, we need the correct topology on the train data. So let's compute it with [Gudhi](https://gudhi.inria.fr/python/latest/). The topology of point clouds can be inferred from several filtrations, so we will use a fast and sparse one (in 2D), namely the [Alpha filtration](https://gudhi.inria.fr/python/latest/alpha_complex_user.html). First, we need to get a sense of the maximal filtration value to use, which we will approximate with the largest pairwise distance of the first 30 point clouds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa0ef6b8",
      "metadata": {
        "id": "fa0ef6b8"
      },
      "outputs": [],
      "source": [
        "ds = [pairwise_distances(X).flatten() for X in data_train[:30]]\n",
        "maxd = np.max(np.concatenate(ds))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c83f64b",
      "metadata": {
        "id": "2c83f64b"
      },
      "source": [
        "#### Persistence diagrams\n",
        "Now, we can compute the persistence diagrams (in homology dimension 1) of the train, clean test and noisy test point clouds!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2048d521",
      "metadata": {
        "id": "2048d521"
      },
      "outputs": [],
      "source": [
        "PD_train = []\n",
        "for X in tqdm(data_train):\n",
        "    st = gd.AlphaComplex(points=X).create_simplex_tree(max_alpha_square=maxd)\n",
        "    st.persistence()\n",
        "    dg = st.persistence_intervals_in_dimension(1)\n",
        "    if len(dg) == 0:\n",
        "        dg = np.empty([0,2])\n",
        "    PD_train.append(dg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c803c26",
      "metadata": {
        "id": "4c803c26"
      },
      "outputs": [],
      "source": [
        "clean_PD_test = []\n",
        "for X in tqdm(clean_data_test):\n",
        "    st = gd.AlphaComplex(points=X).create_simplex_tree(max_alpha_square=maxd)\n",
        "    st.persistence()\n",
        "    dg = st.persistence_intervals_in_dimension(1)\n",
        "    if len(dg) == 0:\n",
        "        dg = np.empty([0,2])\n",
        "    clean_PD_test.append(dg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "014910fd",
      "metadata": {
        "id": "014910fd"
      },
      "outputs": [],
      "source": [
        "noisy_PD_test = []\n",
        "for X in tqdm(noisy_data_test):\n",
        "    st = gd.AlphaComplex(points=X).create_simplex_tree(max_alpha_square=maxd)\n",
        "    st.persistence()\n",
        "    dg = st.persistence_intervals_in_dimension(1)\n",
        "    if len(dg) == 0:\n",
        "        dg = np.empty([0,2])\n",
        "    noisy_PD_test.append(dg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ec6ecfc",
      "metadata": {
        "id": "5ec6ecfc"
      },
      "source": [
        "#### Persistence Image & Persistence Landscape\n",
        "RipsNet actually works on vectorizations of persistence diagrams (PDs), so we will try two: the [persistence image](https://jmlr.org/papers/volume18/16-337/16-337.pdf), and the [persistence landscape](https://jmlr.csail.mit.edu/papers/volume16/bubenik15a/bubenik15a.pdf). First, let's filter out any PD point with infinite coordinates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7060d9f7",
      "metadata": {
        "id": "7060d9f7"
      },
      "outputs": [],
      "source": [
        "pds_train      = DiagramSelector(use=True).fit_transform(PD_train)\n",
        "clean_pds_test = DiagramSelector(use=True).fit_transform(clean_PD_test)\n",
        "noisy_pds_test = DiagramSelector(use=True).fit_transform(noisy_PD_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61c9fa91",
      "metadata": {
        "id": "61c9fa91"
      },
      "source": [
        "Fortunately, Gudhi also has code for computing vectorizations!! However, before launching the computations, we have to estimate a few parameters: the image bandwidth (taken as the 20% quantile of the positive birth-persistence-transformed-PD pairwise distances),\n",
        "and the image and landscape limits (taken as the min and max of birth-persistence-transformed-PD point coordinates)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a967aba2",
      "metadata": {
        "id": "a967aba2"
      },
      "outputs": [],
      "source": [
        "vpdtr = np.vstack(pds_train)\n",
        "pers = vpdtr[:,1]-vpdtr[:,0]\n",
        "bps_pairs = pairwise_distances(np.hstack([vpdtr[:,0:1],vpdtr[:,1:2]-vpdtr[:,0:1]])[:200]).flatten()\n",
        "ppers = bps_pairs[np.argwhere(bps_pairs > 1e-5).ravel()]\n",
        "sigma = np.quantile(ppers, .2)\n",
        "im_bnds = [np.quantile(vpdtr[:,0],0.), np.quantile(vpdtr[:,0],1.), np.quantile(pers,0.), np.quantile(pers,1.)]\n",
        "sp_bnds = [np.quantile(vpdtr[:,0],0.), np.quantile(vpdtr[:,1],1.)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96769d25",
      "metadata": {
        "id": "96769d25"
      },
      "source": [
        "We can now compute and normalize the vectorizations (this can help RipsNet training)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f40a7f03",
      "metadata": {
        "id": "f40a7f03"
      },
      "outputs": [],
      "source": [
        "if 'im_bnds' not in locals() or im_bnds is None:\n",
        "    all_points = np.concatenate(pds_train, axis=0)\n",
        "    x_min, x_max = np.min(all_points[:, 0]), np.max(all_points[:, 0])\n",
        "    y_min, y_max = np.min(all_points[:, 1]), np.max(all_points[:, 1])\n",
        "    im_bnds = [x_min, x_max, y_min, y_max]\n",
        "\n",
        "PI_params = {\n",
        "    'bandwidth': sigma,\n",
        "    'weight': lambda x: 10 * np.tanh(x[1]),\n",
        "    'resolution': [50, 50],\n",
        "    'im_range': im_bnds\n",
        "}\n",
        "\n",
        "PI = PersistenceImage(**PI_params)\n",
        "PI.fit(pds_train)\n",
        "\n",
        "PI_train = PI.transform(pds_train)\n",
        "clean_PI_test = PI.transform(clean_pds_test)\n",
        "noisy_PI_test = PI.transform(noisy_pds_test)\n",
        "\n",
        "MPI = np.max(PI_train)\n",
        "if MPI == 0 or np.isnan(MPI):\n",
        "    raise ValueError(\"MPI (max value) is zero or NaN; check persistence diagrams.\")\n",
        "else:\n",
        "    PI_train /= MPI\n",
        "    clean_PI_test /= MPI\n",
        "    noisy_PI_test /= MPI\n",
        "\n",
        "PI_train = torch.tensor(PI_train, dtype=torch.float32)\n",
        "clean_PI_test = torch.tensor(clean_PI_test, dtype=torch.float32)\n",
        "noisy_PI_test = torch.tensor(noisy_PI_test, dtype=torch.float32)\n",
        "\n",
        "print(f\"PI_train shape: {PI_train.shape}\")\n",
        "print(f\"clean_PI_test shape: {clean_PI_test.shape}\")\n",
        "print(f\"noisy_PI_test shape: {noisy_PI_test.shape}\")\n",
        "print(f\"Max pixel intensity (MPI): {MPI:.5f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac507b7f",
      "metadata": {
        "id": "ac507b7f"
      },
      "outputs": [],
      "source": [
        "\n",
        "if 'sp_bnds' not in locals() or sp_bnds is None:\n",
        "    all_points = np.concatenate(pds_train, axis=0)\n",
        "    x_min, x_max = np.min(all_points[:, 0]), np.max(all_points[:, 1])\n",
        "    sp_bnds = [x_min, x_max]\n",
        "\n",
        "\n",
        "PL_params = {\n",
        "    'num_landscapes': 5,\n",
        "    'resolution': 300,\n",
        "    'sample_range': sp_bnds\n",
        "}\n",
        "\n",
        "PL = Landscape(**PL_params)\n",
        "PL.fit(pds_train)\n",
        "\n",
        "PL_train = PL.transform(pds_train)\n",
        "clean_PL_test = PL.transform(clean_pds_test)\n",
        "noisy_PL_test = PL.transform(noisy_pds_test)\n",
        "\n",
        "MPL = np.max(PL_train)\n",
        "if MPL == 0 or np.isnan(MPL):\n",
        "    raise ValueError(\"MPL (max landscape value) is zero or NaN; check your persistence diagrams.\")\n",
        "else:\n",
        "    PL_train /= MPL\n",
        "    clean_PL_test /= MPL\n",
        "    noisy_PL_test /= MPL\n",
        "\n",
        "PL_train = torch.tensor(PL_train, dtype=torch.float32)\n",
        "clean_PL_test = torch.tensor(clean_PL_test, dtype=torch.float32)\n",
        "noisy_PL_test = torch.tensor(noisy_PL_test, dtype=torch.float32)\n",
        "\n",
        "print(f\"PL_train shape: {PL_train.shape}\")\n",
        "print(f\"clean_PL_test shape: {clean_PL_test.shape}\")\n",
        "print(f\"noisy_PL_test shape: {noisy_PL_test.shape}\")\n",
        "print(f\"Max landscape value (MPL): {MPL:.5f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69b64e49",
      "metadata": {
        "id": "69b64e49"
      },
      "source": [
        "### Time to Train !\n",
        "It is finally time to train RipsNet! We will do it with Pytorch, and custom DeepSet operations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b52c9bd1",
      "metadata": {
        "id": "b52c9bd1"
      },
      "source": [
        "First, let's convert the point clouds into ragged tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d783f99",
      "metadata": {
        "id": "4d783f99"
      },
      "outputs": [],
      "source": [
        "tf_data_train = [torch.tensor(pc, dtype=torch.float32) for pc in data_train]\n",
        "tf_clean_data_test = [torch.tensor(pc, dtype=torch.float32) for pc in clean_data_test]\n",
        "tf_noisy_data_test = [torch.tensor(pc, dtype=torch.float32) for pc in noisy_data_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90928588",
      "metadata": {
        "id": "90928588"
      },
      "source": [
        "Next, we define our RipsNet architecture for learning persistence images, a sequence of fully-connected DeepSet layers, with ReLu activations, Adamax optimizer, and early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bc62bf0",
      "metadata": {
        "id": "5bc62bf0"
      },
      "outputs": [],
      "source": [
        "output_dim = PI_train.shape[1]\n",
        "model_PI = RaggedPersistenceModel(output_dim=output_dim)\n",
        "\n",
        "optimizer = Adamax(model_PI.parameters(), lr=5e-4)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56ca6155",
      "metadata": {
        "id": "56ca6155"
      },
      "source": [
        "Time to learn!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "568d3152",
      "metadata": {
        "id": "568d3152"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_model(model, optimizer, criterion, train_inputs, train_targets, val_inputs, val_targets, epochs=20, batch_size=32):\n",
        "    \"\"\"\n",
        "    Train a ragged-input model. Returns (best_model, history, best_model_state).\n",
        "    \"\"\"\n",
        "    model = model.to(device)\n",
        "    patience = 200\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    num_epochs = epochs if epochs is not None else 10000\n",
        "    history = {'train_loss': [], 'val_loss': []}\n",
        "    best_model_state = None\n",
        "\n",
        "    # helper to move inputs to device\n",
        "    def to_device_list(lst):\n",
        "        out = []\n",
        "        for x in lst:\n",
        "            if isinstance(x, torch.Tensor):\n",
        "                out.append(x.to(device).float())\n",
        "            else:\n",
        "                out.append(torch.tensor(x, dtype=torch.float32, device=device))\n",
        "        return out\n",
        "\n",
        "    train_inputs = to_device_list(train_inputs)\n",
        "    val_inputs = to_device_list(val_inputs)\n",
        "\n",
        "    if isinstance(train_targets, torch.Tensor):\n",
        "        train_targets = train_targets.to(device).float()\n",
        "    else:\n",
        "        train_targets = torch.tensor(train_targets, dtype=torch.float32, device=device)\n",
        "\n",
        "    if isinstance(val_targets, torch.Tensor):\n",
        "        val_targets = val_targets.to(device).float()\n",
        "    else:\n",
        "        val_targets = torch.tensor(val_targets, dtype=torch.float32, device=device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        permutation = torch.randperm(len(train_inputs), device=device)\n",
        "        epoch_loss = 0.0\n",
        "        for i in range(0, len(train_inputs), batch_size):\n",
        "            optimizer.zero_grad()\n",
        "            indices = permutation[i:i + batch_size]\n",
        "            batch_inputs = [train_inputs[int(idx)].to(device) for idx in indices]\n",
        "            batch_targets = train_targets[indices]\n",
        "\n",
        "            outputs = model(batch_inputs)\n",
        "            if isinstance(outputs, (list, tuple)):\n",
        "                outputs = outputs[0]\n",
        "            if not isinstance(outputs, torch.Tensor):\n",
        "                outputs = torch.tensor(outputs, dtype=batch_targets.dtype, device=device)\n",
        "            else:\n",
        "                outputs = outputs.to(device).type(batch_targets.dtype)\n",
        "\n",
        "            loss = criterion(outputs, batch_targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item() * len(batch_inputs)\n",
        "\n",
        "        epoch_loss /= len(train_inputs)\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_outputs = model(val_inputs)\n",
        "            if isinstance(val_outputs, (list, tuple)):\n",
        "                val_outputs = val_outputs[0]\n",
        "            val_outputs = val_outputs.to(device).type(val_targets.dtype)\n",
        "            val_loss = criterion(val_outputs, val_targets).item()\n",
        "            history['val_loss'].append(val_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.6f}, Val Loss: {val_loss:.6f}')\n",
        "\n",
        "        if val_loss < best_val_loss - 1e-5:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            # save best model (on CPU to avoid holding GPU memory)\n",
        "            best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    # if we saved a best state, load it back into the model on the current device\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict({k: v.to(device) for k, v in best_model_state.items()})\n",
        "\n",
        "    return model, history, best_model_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76e1c61b",
      "metadata": {
        "id": "76e1c61b"
      },
      "outputs": [],
      "source": [
        "# Training RipsNet to predict Persistence Images (original training loop)\n",
        "model = model_PI\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adamax(model_PI.parameters(), lr=5e-4)\n",
        "train_inputs = [torch.tensor(x, dtype=torch.float32).to(device) for x in tf_data_train]\n",
        "train_targets = torch.tensor(PI_train, dtype=torch.float32).to(device)\n",
        "val_inputs = [torch.tensor(x, dtype=torch.float32).to(device) for x in tf_clean_data_test]\n",
        "val_targets = torch.tensor(clean_PI_test, dtype=torch.float32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a46c2f78",
      "metadata": {
        "id": "a46c2f78"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Redefining DenseRagged to correctly handle device placement of dynamically created parameters\n",
        "class DenseRagged(nn.Module):\n",
        "    def __init__(self, in_features=None, out_features=30, activation='relu', use_bias=True):\n",
        "        super(DenseRagged, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.use_bias = use_bias\n",
        "        self.activation = activation\n",
        "\n",
        "        # Parameters will be initialized on first forward pass.\n",
        "        self.weight_param = None # Use distinct names for registered parameters\n",
        "        self.bias_param = None\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = []\n",
        "        for x in inputs:\n",
        "            if self.weight_param is None: # Check if parameters have been initialized\n",
        "                in_features = x.shape[-1]\n",
        "                # Initialize weight on the same device as input x\n",
        "                self.weight_param = nn.Parameter(torch.randn(in_features, self.out_features, device=x.device) * 0.01)\n",
        "                self.register_parameter('weight_param', self.weight_param) # Register the parameter\n",
        "                if self.use_bias:\n",
        "                    # Initialize bias on the same device as input x\n",
        "                    self.bias_param = nn.Parameter(torch.zeros(self.out_features, device=x.device))\n",
        "                    self.register_parameter('bias_param', self.bias_param) # Register the parameter\n",
        "\n",
        "            y = torch.matmul(x, self.weight_param) # Use the registered parameter\n",
        "            if self.use_bias:\n",
        "                y = y + self.bias_param # Use the registered parameter\n",
        "            if self.activation == 'relu':\n",
        "                y = F.relu(y)\n",
        "            elif self.activation == 'sigmoid':\n",
        "                y = torch.sigmoid(y)\n",
        "            elif self.activation == 'tanh':\n",
        "                y = torch.tanh(y)\n",
        "            outputs.append(y)\n",
        "        return outputs\n",
        "\n",
        "# Redefining PermopRagged (no changes needed, but must be in scope if RaggedPersistenceModel is redefined)\n",
        "class PermopRagged(nn.Module):\n",
        "    def forward(self, inputs):\n",
        "        return torch.stack([torch.sum(x, dim=0) for x in inputs])\n",
        "\n",
        "# Redefining RaggedPersistenceModel to use the corrected DenseRagged\n",
        "class RaggedPersistenceModel(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super(RaggedPersistenceModel, self).__init__()\n",
        "        self.ragged_layers = nn.ModuleList([\n",
        "            DenseRagged(out_features=30, activation='relu'),\n",
        "            DenseRagged(out_features=20, activation='relu'),\n",
        "            DenseRagged(out_features=10, activation='relu')\n",
        "        ])\n",
        "        self.perm = PermopRagged()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(10, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 200),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(200, output_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.ragged_layers:\n",
        "            x = layer(x)\n",
        "        x = self.perm(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Re-instantiate model_PI with the new class definition\n",
        "output_dim = PI_train.shape[1]\n",
        "model_PI = RaggedPersistenceModel(output_dim=output_dim)\n",
        "\n",
        "# Re-prepare inputs to avoid UserWarnings and ensure they are on the correct device.\n",
        "# Assuming tf_data_train, PI_train, tf_clean_data_test, clean_PI_test are correctly defined\n",
        "# and `device` is set up.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_inputs = [pc.to(device) for pc in tf_data_train]\n",
        "train_targets = PI_train.to(device)\n",
        "val_inputs = [pc.to(device) for pc in tf_clean_data_test]\n",
        "val_targets = clean_PI_test.to(device)\n",
        "\n",
        "# Redefine optimizer here to use the new model_PI parameters.\n",
        "optimizer = Adamax(model_PI.parameters(), lr=5e-4)\n",
        "criterion = nn.MSELoss() # Criterion remains the same\n",
        "\n",
        "# Ensure num_epochs is defined\n",
        "try:\n",
        "    num_epochs\n",
        "except NameError:\n",
        "    num_epochs = 10000\n",
        "\n",
        "model_PI, history_PI, best_model_state = train_model(\n",
        "    model_PI, optimizer, criterion,\n",
        "    train_inputs, train_targets,\n",
        "    val_inputs, val_targets,\n",
        "    epochs=num_epochs, batch_size=32\n",
        ")\n",
        "\n",
        "best_val_loss = min(history_PI['val_loss']) if history_PI.get('val_loss') else float('inf')\n",
        "print(f\"Training complete. Best val_loss = {best_val_loss:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628f84eb",
      "metadata": {
        "id": "628f84eb"
      },
      "source": [
        "Learning is done! The advantage of RipsNet is that we can now use it to predict persistence images directly from point clouds in the blink of an eye!Let's see how accurate the predictions of RipsNet really are, at least on the train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea151246",
      "metadata": {
        "id": "ea151246"
      },
      "outputs": [],
      "source": [
        "model_PI.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # ensure inputs have the same dtype as the model parameters (float32)\n",
        "    train_inputs = [torch.tensor(x, dtype=torch.float32).to(device) for x in tf_data_train]\n",
        "    clean_inputs = [torch.tensor(x, dtype=torch.float32).to(device) for x in tf_clean_data_test]\n",
        "    noisy_inputs = [torch.tensor(x, dtype=torch.float32).to(device) for x in tf_noisy_data_test]\n",
        "\n",
        "    train_PI_prediction = model_PI(train_inputs).cpu().numpy()\n",
        "    clean_PI_prediction = model_PI(clean_inputs).cpu().numpy()\n",
        "    noisy_PI_prediction = model_PI(noisy_inputs).cpu().numpy()\n",
        "\n",
        "print(\"Predictions computed:\")\n",
        "print(f\"train_PI_prediction shape: {train_PI_prediction.shape}\")\n",
        "print(f\"clean_PI_prediction shape: {clean_PI_prediction.shape}\")\n",
        "print(f\"noisy_PI_prediction shape: {noisy_PI_prediction.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "490db24c",
      "metadata": {
        "id": "490db24c"
      },
      "source": [
        "Pretty good actually! Let's look at the test set now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "055986cc",
      "metadata": {
        "id": "055986cc"
      },
      "outputs": [],
      "source": [
        "def to_numpy(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.detach().cpu().numpy()\n",
        "    return np.array(x)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(3, 3, wspace=0.0, hspace=0.0)\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        idx = 3 * i + j\n",
        "        ax = plt.subplot(gs[i, j])\n",
        "\n",
        "        try:\n",
        "            data = to_numpy(tf_noisy_data_test[idx])\n",
        "            if data.shape[1] != 2:\n",
        "                print(f\"Skipping idx={idx}, unexpected shape: {data.shape}\")\n",
        "                continue\n",
        "            ax.scatter(data[:, 0], data[:, 1], s=3)\n",
        "        except Exception as e:\n",
        "            print(f\"Error at idx={idx} in noisy point cloud: {e}\")\n",
        "            continue\n",
        "\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "plt.savefig(\"noisy_gudhi_pc.png\", bbox_inches=\"tight\")\n",
        "print(\"Saved noisy_gudhi_pc.png\")\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(3, 3, wspace=0.0, hspace=0.0)\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        idx = 3 * i + j\n",
        "        ax = plt.subplot(gs[i, j])\n",
        "\n",
        "        arr = np.array(noisy_PI_test[idx])\n",
        "        if arr.size != 50*50:\n",
        "            print(f\"Skipping idx={idx}, unexpected size: {arr.size}\")\n",
        "            continue\n",
        "\n",
        "        im = np.flip(arr.reshape(50, 50), 0)  # vertical flip\n",
        "        ax.imshow(im, cmap=\"jet\")\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "plt.savefig(\"noisy_gudhi_pi.png\", bbox_inches=\"tight\")\n",
        "print(\"Saved noisy_gudhi_pi.png\")\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(3, 3, wspace=0.0, hspace=0.0)\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        idx = 3 * i + j\n",
        "        ax = plt.subplot(gs[i, j])\n",
        "\n",
        "        arr = np.array(noisy_PI_prediction[idx])\n",
        "        if arr.size != 50*50:\n",
        "            print(f\"Skipping idx={idx}, unexpected size: {arr.size}\")\n",
        "            continue\n",
        "\n",
        "        pred = np.flip(arr.reshape(50, 50), 0)\n",
        "        ax.imshow(pred, cmap=\"jet\")\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "plt.savefig(\"noisy_ripsnet_pi.png\", bbox_inches=\"tight\")\n",
        "print(\"Saved noisy_ripsnet_pi.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1355662",
      "metadata": {
        "id": "a1355662"
      },
      "source": [
        "Yep, even though Gudhi now produces bad images because of the ambiant noise, RipsNet predictions still look rather good. Another way to quantify this is to see the difference between classifiers predicting the number of circles that are trained either from Gudhi or from RipsNet predictions. Let's first see how an XGBoost model performs when using Gudhi descriptors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6823b51",
      "metadata": {
        "id": "a6823b51"
      },
      "outputs": [],
      "source": [
        "model_classif_gudhi = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "model_classif_gudhi.fit(PI_train, label_classif_train)\n",
        "clean_test_acc_gudhi = model_classif_gudhi.score(clean_PI_test, clean_label_classif_test)\n",
        "noisy_test_acc_gudhi = model_classif_gudhi.score(noisy_PI_test, noisy_label_classif_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "383c3e4a",
      "metadata": {
        "id": "383c3e4a"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy on clean test set = \" + str(clean_test_acc_gudhi))\n",
        "print(\"Accuracy on noisy test set = \" + str(noisy_test_acc_gudhi))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18d14586",
      "metadata": {
        "id": "18d14586"
      },
      "source": [
        "Well, the classifier definitely does well on clean data but struggles on noisy data. Let's see how another classifier trained on RipsNet descriptors now performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bf469d5",
      "metadata": {
        "id": "1bf469d5"
      },
      "outputs": [],
      "source": [
        "# ensure labels match the augmented training set size\n",
        "# `le` was fitted earlier; label_train was augmented to match train inputs\n",
        "label_classif_train_aug = le.transform(label_train)\n",
        "\n",
        "model_classif_RN = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "model_classif_RN.fit(train_PI_prediction, label_classif_train_aug)\n",
        "clean_test_acc_RN = model_classif_RN.score(clean_PI_prediction, clean_label_classif_test)\n",
        "noisy_test_acc_RN = model_classif_RN.score(noisy_PI_prediction, noisy_label_classif_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9991e9a6",
      "metadata": {
        "id": "9991e9a6"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy on clean test set = \" + str(clean_test_acc_RN))\n",
        "print(\"Accuracy on noisy test set = \" + str(noisy_test_acc_RN))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59c9e7ef",
      "metadata": {
        "id": "59c9e7ef"
      },
      "source": [
        "Well, even though the accuracy is slightly worse on clean data, it does remarkably well when noise is added! This illustrates the robustness of RipsNet-based topological descriptors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9ef919",
      "metadata": {
        "id": "be9ef919"
      },
      "source": [
        "Now, let's play the same game with persistence landscapes, using the same architecture (except for the dimension of the final layer of course). In the three following cells, we define RipsNet, train it on landscapes, and use it to predict persistence landscapes from the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1e8ae16",
      "metadata": {
        "id": "f1e8ae16"
      },
      "outputs": [],
      "source": [
        "output_dim = PL_train.shape[1]\n",
        "model_PL = RaggedPersistenceModel(output_dim=output_dim)\n",
        "\n",
        "optimizer = Adamax(model_PL.parameters(), lr=5e-4)\n",
        "criterion = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf29241",
      "metadata": {
        "id": "fcf29241"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_PL = model_PL.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adamax(model_PL.parameters(), lr=5e-4)\n",
        "\n",
        "patience = 200\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "num_epochs = 10000\n",
        "\n",
        "# prepare data once (move to device)\n",
        "train_inputs = [x.to(device).float() if isinstance(x, torch.Tensor) else torch.tensor(x, dtype=torch.float32, device=device) for x in tf_data_train]\n",
        "train_targets = torch.tensor(PL_train, dtype=torch.float32, device=device)\n",
        "\n",
        "val_inputs = [x.to(device).float() if isinstance(x, torch.Tensor) else torch.tensor(x, dtype=torch.float32, device=device) for x in tf_clean_data_test]\n",
        "val_targets = torch.tensor(clean_PL_test, dtype=torch.float32, device=device)\n",
        "\n",
        "history = {'train_loss': [], 'val_loss': []}\n",
        "best_model_state = {k: v.cpu() for k, v in model_PL.state_dict().items()}\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model_PL.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model_PL(train_inputs)\n",
        "    if isinstance(outputs, (list, tuple)):\n",
        "        outputs = outputs[0]\n",
        "    if outputs is None:\n",
        "        raise RuntimeError(\"model_PL returned None\")\n",
        "    if not isinstance(outputs, torch.Tensor):\n",
        "        outputs = torch.tensor(outputs, dtype=train_targets.dtype, device=train_targets.device)\n",
        "    else:\n",
        "        outputs = outputs.to(train_targets.device).type(train_targets.dtype)\n",
        "\n",
        "    loss = criterion(outputs, train_targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    model_PL.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model_PL(val_inputs)\n",
        "        if isinstance(val_outputs, (list, tuple)):\n",
        "            val_outputs = val_outputs[0]\n",
        "        val_outputs = val_outputs.to(val_targets.device).type(val_targets.dtype)\n",
        "        val_loss = criterion(val_outputs, val_targets)\n",
        "\n",
        "    history['train_loss'].append(loss.item())\n",
        "    history['val_loss'].append(val_loss.item())\n",
        "\n",
        "    if val_loss.item() < best_val_loss - 1e-5:\n",
        "        best_val_loss = val_loss.item()\n",
        "        patience_counter = 0\n",
        "        # save on CPU to avoid GPU memory hold\n",
        "        best_model_state = {k: v.cpu().clone() for k, v in model_PL.state_dict().items()}\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch+1}\")\n",
        "        break\n",
        "\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train loss: {loss.item():.6f}, Val loss: {val_loss.item():.6f}\")\n",
        "\n",
        "# load best weights back to device\n",
        "model_PL.load_state_dict({k: v.to(device) for k, v in best_model_state.items()})\n",
        "print(f\"Training complete. Best val_loss = {best_val_loss:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a12893b",
      "metadata": {
        "id": "5a12893b"
      },
      "outputs": [],
      "source": [
        "model_PL.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_inputs = [torch.tensor(x, dtype=torch.float32).to(device) for x in tf_data_train]\n",
        "    clean_inputs = [torch.tensor(x, dtype=torch.float32).to(device) for x in tf_clean_data_test]\n",
        "    noisy_inputs = [torch.tensor(x, dtype=torch.float32).to(device) for x in tf_noisy_data_test]\n",
        "\n",
        "    train_PL_prediction = model_PL(train_inputs).cpu().numpy()\n",
        "    clean_PL_prediction = model_PL(clean_inputs).cpu().numpy()\n",
        "    noisy_PL_prediction = model_PL(noisy_inputs).cpu().numpy()\n",
        "\n",
        "print(\"Predictions computed:\")\n",
        "print(f\"train_PI_prediction shape: {train_PL_prediction.shape}\")\n",
        "print(f\"clean_PI_prediction shape: {clean_PL_prediction.shape}\")\n",
        "print(f\"noisy_PI_prediction shape: {noisy_PL_prediction.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a18b01e5",
      "metadata": {
        "id": "a18b01e5"
      },
      "source": [
        "Let's see how good RipsNet is for landscapes now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bfcfcc4",
      "metadata": {
        "id": "2bfcfcc4"
      },
      "outputs": [],
      "source": [
        "def to_numpy(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.detach().cpu().numpy()\n",
        "    return np.array(x)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(3, 3, wspace=0.0, hspace=0.0)\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        idx = 3 * i + j\n",
        "        ax = plt.subplot(gs[i, j])\n",
        "\n",
        "        try:\n",
        "            data = to_numpy(tf_clean_data_test[idx])\n",
        "            if data.shape[1] != 2:\n",
        "                print(f\"Skipping idx={idx}, unexpected shape: {data.shape}\")\n",
        "                continue\n",
        "            ax.scatter(data[:, 0], data[:, 1], s=3)\n",
        "        except Exception as e:\n",
        "            print(f\"Error at idx={idx} in point cloud: {e}\")\n",
        "            continue\n",
        "\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "plt.savefig('clean_gudhi_pc.png', bbox_inches='tight')\n",
        "print(\"Saved clean_gudhi_pc.png\")\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(3, 3, wspace=0.0, hspace=0.0)\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        idx = 3 * i + j\n",
        "        ax = plt.subplot(gs[i, j])\n",
        "\n",
        "        arr = np.array(clean_PL_test[idx])\n",
        "        if arr.size != 50*50:\n",
        "            print(f\"Skipping idx={idx}, unexpected size: {arr.size}\")\n",
        "            continue\n",
        "\n",
        "        im = np.flip(arr.reshape(50, 50), 0)  # vertical flip\n",
        "        ax.imshow(im, cmap='jet')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "plt.savefig('clean_gudhi_pl.png', bbox_inches='tight')\n",
        "print(\"Saved clean_gudhi_pl.png\")\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(3, 3, wspace=0.0, hspace=0.0)\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        idx = 3 * i + j\n",
        "        ax = plt.subplot(gs[i, j])\n",
        "\n",
        "        arr = np.array(clean_PL_prediction[idx])\n",
        "        if arr.size != 50*50:\n",
        "            print(f\"Skipping idx={idx}, unexpected size: {arr.size}\")\n",
        "            continue\n",
        "\n",
        "        pred = np.flip(arr.reshape(50, 50), 0)\n",
        "        ax.imshow(pred, cmap='jet')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "plt.savefig('clean_ripsnet_pl.png', bbox_inches='tight')\n",
        "print(\"Saved clean_ripsnet_pl.png\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ca63ef4",
      "metadata": {
        "id": "8ca63ef4"
      },
      "outputs": [],
      "source": [
        "def to_numpy(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.detach().cpu().numpy()\n",
        "    return np.array(x)\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(3, 3, wspace=0.0, hspace=0.0)\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        idx = 3 * i + j\n",
        "        ax = plt.subplot(gs[i, j])\n",
        "\n",
        "        try:\n",
        "            data = to_numpy(tf_noisy_data_test[idx])\n",
        "            if data.shape[1] != 2:\n",
        "                print(f\"Skipping idx={idx}, unexpected shape: {data.shape}\")\n",
        "                continue\n",
        "            ax.scatter(data[:, 0], data[:, 1], s=3)\n",
        "        except Exception as e:\n",
        "            print(f\"Error at idx={idx} in noisy point cloud: {e}\")\n",
        "            continue\n",
        "\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "plt.savefig(\"noisy_gudhi_pc.png\", bbox_inches=\"tight\")\n",
        "print(\"Saved noisy_gudhi_pc.png\")\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(3, 3, wspace=0.0, hspace=0.0)\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        idx = 3 * i + j\n",
        "        ax = plt.subplot(gs[i, j])\n",
        "\n",
        "        arr = np.array(noisy_PL_test[idx])\n",
        "        if arr.size != 50*50:\n",
        "            print(f\"Skipping idx={idx}, unexpected size: {arr.size}\")\n",
        "            continue\n",
        "\n",
        "        im = np.flip(arr.reshape(50, 50), 0)  # vertical flip\n",
        "        ax.imshow(im, cmap=\"jet\")\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "plt.savefig(\"noisy_gudhi_pl.png\", bbox_inches=\"tight\")\n",
        "print(\"Saved noisy_gudhi_pl.png\")\n",
        "\n",
        "fig = plt.figure(figsize=(10, 10))\n",
        "gs = gridspec.GridSpec(3, 3, wspace=0.0, hspace=0.0)\n",
        "\n",
        "for i in range(3):\n",
        "    for j in range(3):\n",
        "        idx = 3 * i + j\n",
        "        ax = plt.subplot(gs[i, j])\n",
        "\n",
        "        arr = np.array(noisy_PL_prediction[idx])\n",
        "        if arr.size != 50*50:\n",
        "            print(f\"Skipping idx={idx}, unexpected size: {arr.size}\")\n",
        "            continue\n",
        "\n",
        "        pred = np.flip(arr.reshape(50, 50), 0)\n",
        "        ax.imshow(pred, cmap=\"jet\")\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "plt.savefig(\"noisy_ripsnet_pl.png\", bbox_inches=\"tight\")\n",
        "print(\"Saved noisy_ripsnet_pl.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be4eb5f7",
      "metadata": {
        "id": "be4eb5f7"
      },
      "source": [
        "As before, we end by training XGBoost classifier on both Gudhi and RipsNet generated landscapes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41adf227",
      "metadata": {
        "id": "41adf227"
      },
      "outputs": [],
      "source": [
        "model_classif_gudhi = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "model_classif_gudhi.fit(PL_train, label_classif_train)\n",
        "clean_test_acc_gudhi = model_classif_gudhi.score(clean_PL_test,  clean_label_classif_test)\n",
        "noisy_test_acc_gudhi = model_classif_gudhi.score(noisy_PL_test,  noisy_label_classif_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea9259ec",
      "metadata": {
        "id": "ea9259ec"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy on clean test set = \" + str(clean_test_acc_gudhi))\n",
        "print(\"Accuracy on noisy test set = \" + str(noisy_test_acc_gudhi))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e7933a4",
      "metadata": {
        "id": "1e7933a4"
      },
      "outputs": [],
      "source": [
        "model_classif_RN = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "model_classif_RN.fit(train_PL_prediction, label_classif_train)\n",
        "clean_test_acc_RN = model_classif_RN.score(clean_PL_prediction, clean_label_classif_test)\n",
        "noisy_test_acc_RN = model_classif_RN.score(noisy_PL_prediction, noisy_label_classif_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64e6b518",
      "metadata": {
        "id": "64e6b518"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy on clean test set = \" + str(clean_test_acc_RN))\n",
        "print(\"Accuracy on noisy test set = \" + str(noisy_test_acc_RN))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1ac739d",
      "metadata": {
        "id": "c1ac739d"
      },
      "source": [
        "The difference is less clear than for persistence images, but present nonetheless! Again, RipsNet exhibits better  robustness properties than Gudhi on noise data, while being faster and almost as good on clean data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b967d4b",
      "metadata": {
        "id": "0b967d4b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import List\n",
        "\n",
        "class DistanceMatrixRaggedModel(nn.Module):\n",
        "    def __init__(self, output_dim, num_points=None, phi_dim=128, rho_hidden=(256,128)):\n",
        "        \"\"\"\n",
        "        output_dim: final descriptor size (e.g., PI_train.shape[1])\n",
        "        num_points: expected number of points (row length). If None, model infers size at first forward.\n",
        "        phi_dim: per-row embedding size\n",
        "        rho_hidden: sizes of hidden layers for global map\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_points = num_points\n",
        "        inp = num_points if num_points is not None else 0\n",
        "        self._phi_layers = None\n",
        "        self.phi_dim = phi_dim\n",
        "        self._build_phi(inp)\n",
        "        layers = []\n",
        "        prev = phi_dim\n",
        "        for h in rho_hidden:\n",
        "            layers.append(nn.Linear(prev, h))\n",
        "            layers.append(nn.ReLU())\n",
        "            prev = h\n",
        "        layers.append(nn.Linear(prev, output_dim))\n",
        "        self.rho = nn.Sequential(*layers)\n",
        "\n",
        "    def _build_phi(self, inp):\n",
        "        if inp <= 0:\n",
        "            self._phi_layers = None\n",
        "            return\n",
        "        hidden = max(64, self.phi_dim)\n",
        "        self._phi_layers = nn.Sequential(\n",
        "            nn.Linear(inp, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, self.phi_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, batch: List[torch.Tensor]):\n",
        "        \"\"\"\n",
        "        batch: list of (Ni x Ni) distance matrices (torch.Tensor)\n",
        "        returns: (B, output_dim)\n",
        "        \"\"\"\n",
        "        if len(batch) == 0:\n",
        "            return torch.empty(0, self.rho[-1].out_features, device=next(self.parameters()).device)\n",
        "\n",
        "        sizes = [m.shape[0] for m in batch]\n",
        "        max_n = max(sizes)\n",
        "        device = next(self.parameters()).device\n",
        "\n",
        "        if self._phi_layers is None or (self.num_points and self.num_points != max_n):\n",
        "            self._build_phi(max_n)\n",
        "            self.num_points = max_n\n",
        "            self._phi_layers = self._phi_layers.to(device)\n",
        "\n",
        "        B = len(batch)\n",
        "        mats = torch.zeros((B, max_n, max_n), dtype=torch.float32, device=device)\n",
        "        row_mask = torch.zeros((B, max_n), dtype=torch.bool, device=device)\n",
        "        for i, m in enumerate(batch):\n",
        "            n = m.shape[0]\n",
        "            mats[i, :n, :n] = m.to(device).float()\n",
        "            row_mask[i, :n] = 1\n",
        "\n",
        "        rows = mats.reshape(B * max_n, max_n)\n",
        "        phi_out = self._phi_layers(rows)\n",
        "        phi_out = phi_out.reshape(B, max_n, -1)\n",
        "\n",
        "        lengths = row_mask.sum(dim=1).clamp(min=1).unsqueeze(-1).float()\n",
        "        summed = (phi_out * row_mask.unsqueeze(-1).float()).sum(dim=1)\n",
        "        aggregated = summed / lengths\n",
        "\n",
        "        out = self.rho(aggregated)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62516755"
      },
      "source": [
        "# Task\n",
        "Compute pairwise Euclidean distance matrices for the training and test point clouds, then initialize and train a DistanceMatrixRaggedModel to predict Persistence Images. Afterwards, evaluate its classification accuracy using an XGBoost classifier on clean and noisy test sets. Repeat this process for Persistence Landscapes."
      ],
      "id": "62516755"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8f3f9c2"
      },
      "source": [
        "## Compute distance matrices\n",
        "\n",
        "### Subtask:\n",
        "Compute pairwise Euclidean distance matrices for the training and test point clouds.\n"
      ],
      "id": "f8f3f9c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2e3da56"
      },
      "source": [
        "**Reasoning**:\n",
        "I will apply the `distance_matrix` function to each point cloud in `data_train`, `clean_data_test`, and `noisy_data_test` to compute the pairwise Euclidean distance matrices for the respective datasets. I will use `tqdm` to display progress during the computation.\n",
        "\n"
      ],
      "id": "c2e3da56"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df689f82"
      },
      "source": [
        "dm_train = []\n",
        "for X in tqdm(data_train, desc='Computing DM for training data'):\n",
        "    dm_train.append(distance_matrix(X))\n",
        "\n",
        "dm_clean_test = []\n",
        "for X in tqdm(clean_data_test, desc='Computing DM for clean test data'):\n",
        "    dm_clean_test.append(distance_matrix(X))\n",
        "\n",
        "dm_noisy_test = []\n",
        "for X in tqdm(noisy_data_test, desc='Computing DM for noisy test data'):\n",
        "    dm_noisy_test.append(distance_matrix(X))\n",
        "\n",
        "print(f\"Shape of first training distance matrix: {dm_train[0].shape}\")\n",
        "print(f\"Shape of first clean test distance matrix: {dm_clean_test[0].shape}\")\n",
        "print(f\"Shape of first noisy test distance matrix: {dm_noisy_test[0].shape}\")"
      ],
      "id": "df689f82",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bd56ff6"
      },
      "source": [
        "**Reasoning**:\n",
        "I will apply the `distance_matrix` function to each point cloud in `data_train`, `clean_data_test`, and `noisy_data_test` to compute the pairwise Euclidean distance matrices for the respective datasets. I will use `tqdm` to display progress during the computation.\n",
        "\n"
      ],
      "id": "8bd56ff6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaa96738"
      },
      "source": [
        "dm_train = []\n",
        "for X in tqdm(data_train, desc='Computing DM for training data'):\n",
        "    dm_train.append(distance_matrix(X))\n",
        "\n",
        "dm_clean_test = []\n",
        "for X in tqdm(clean_data_test, desc='Computing DM for clean test data'):\n",
        "    dm_clean_test.append(distance_matrix(X))\n",
        "\n",
        "dm_noisy_test = []\n",
        "for X in tqdm(noisy_data_test, desc='Computing DM for noisy test data'):\n",
        "    dm_noisy_test.append(distance_matrix(X))\n",
        "\n",
        "print(f\"Shape of first training distance matrix: {dm_train[0].shape}\")\n",
        "print(f\"Shape of first clean test distance matrix: {dm_clean_test[0].shape}\")\n",
        "print(f\"Shape of first noisy test distance matrix: {dm_noisy_test[0].shape}\")"
      ],
      "id": "eaa96738",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4b91f9a"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block was already executed and completed the task of computing distance matrices. The next step is to initialize the `DistanceMatrixRaggedModel` to predict Persistence Images.\n",
        "\n"
      ],
      "id": "b4b91f9a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "516c98b2"
      },
      "source": [
        "output_dim_pi = PI_train.shape[1]\n",
        "model_dm_pi = DistanceMatrixRaggedModel(output_dim=output_dim_pi)\n",
        "\n",
        "print(f\"Initialized DistanceMatrixRaggedModel for PI with output_dim: {output_dim_pi}\")"
      ],
      "id": "516c98b2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed3fc16a"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to train the `DistanceMatrixRaggedModel` for Persistence Images using the pre-computed distance matrices and Persistence Images. I will reuse the `train_model` function defined previously for training with early stopping.\n",
        "\n"
      ],
      "id": "ed3fc16a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eb06b56"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_dm_pi.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = Adamax(model_dm_pi.parameters(), lr=5e-4)\n",
        "\n",
        "# Ensure num_epochs is defined\n",
        "try:\n",
        "    num_epochs\n",
        "except NameError:\n",
        "    num_epochs = 10000\n",
        "\n",
        "model_dm_pi, history_dm_pi, best_model_state_dm_pi = train_model(\n",
        "    model_dm_pi, optimizer, criterion,\n",
        "    dm_train, PI_train,\n",
        "    dm_clean_test, clean_PI_test,\n",
        "    epochs=num_epochs, batch_size=32\n",
        ")\n",
        "\n",
        "best_val_loss_dm_pi = min(history_dm_pi['val_loss']) if history_dm_pi.get('val_loss') else float('inf')\n",
        "print(f\"Training DistanceMatrixRaggedModel for PI complete. Best val_loss = {best_val_loss_dm_pi:.6f}\")"
      ],
      "id": "1eb06b56",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96ea0b33"
      },
      "source": [
        "## Evaluate classification accuracy (PI)\n",
        "\n",
        "### Subtask:\n",
        "Make predictions with the trained `DistanceMatrixRaggedModel` for Persistence Images on clean and noisy test sets. Then, train an XGBoost classifier on these predictions and report the classification accuracy.\n"
      ],
      "id": "96ea0b33"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4c4977e"
      },
      "source": [
        "**Reasoning**:\n",
        "I will make predictions using the trained `DistanceMatrixRaggedModel` on the distance matrices for training, clean test, and noisy test data. Then, I will train an XGBoost classifier on these predictions and report its accuracy on both clean and noisy test sets.\n",
        "\n"
      ],
      "id": "e4c4977e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ed36bf2"
      },
      "source": [
        "model_dm_pi.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Ensure inputs are on the correct device and dtype\n",
        "    # The train_model function already converted dm_train and dm_clean_test to lists of tensors on the device.\n",
        "    # So we only need to handle dm_noisy_test explicitly here if it wasn't already handled for validation.\n",
        "    # However, to be safe and consistent with the train_model's input preparation for evaluation,\n",
        "    # let's re-convert them.\n",
        "    dm_train_tensor = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_train]\n",
        "    dm_clean_test_tensor = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_clean_test]\n",
        "    dm_noisy_test_tensor = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_noisy_test]\n",
        "\n",
        "    dm_train_PI_prediction = model_dm_pi(dm_train_tensor).cpu().numpy()\n",
        "    dm_clean_PI_prediction = model_dm_pi(dm_clean_test_tensor).cpu().numpy()\n",
        "    dm_noisy_PI_prediction = model_dm_pi(dm_noisy_test_tensor).cpu().numpy()\n",
        "\n",
        "print(\"Predictions computed for DistanceMatrixRaggedModel for PI:\")\n",
        "print(f\"dm_train_PI_prediction shape: {dm_train_PI_prediction.shape}\")\n",
        "print(f\"dm_clean_PI_prediction shape: {dm_clean_PI_prediction.shape}\")\n",
        "print(f\"dm_noisy_PI_prediction shape: {dm_noisy_PI_prediction.shape}\")\n",
        "\n",
        "# Train an XGBoost classifier on the predictions\n",
        "model_classif_dm_pi = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "model_classif_dm_pi.fit(dm_train_PI_prediction, label_classif_train)\n",
        "\n",
        "# Evaluate accuracy on clean test set\n",
        "clean_test_acc_dm_pi = model_classif_dm_pi.score(dm_clean_PI_prediction, clean_label_classif_test)\n",
        "print(f\"Accuracy on clean test set : {clean_test_acc_dm_pi}\")\n",
        "\n",
        "# Evaluate accuracy on noisy test set\n",
        "noisy_test_acc_dm_pi = model_classif_dm_pi.score(dm_noisy_PI_prediction, noisy_label_classif_test)\n",
        "print(f\"Accuracy on noisy test set : {noisy_test_acc_dm_pi}\")"
      ],
      "id": "8ed36bf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86c9ded6"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block successfully executed. The next step is to make predictions using the trained `DistanceMatrixRaggedModel` for Persistence Images on the distance matrices for training, clean test, and noisy test data. Then, an XGBoost classifier will be trained on these predictions, and its accuracy will be reported on both clean and noisy test sets, as requested by the subtask.\n",
        "\n"
      ],
      "id": "86c9ded6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "264aeeac"
      },
      "source": [
        "model_dm_pi.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Ensure inputs are on the correct device and dtype\n",
        "    # The train_model function already converted dm_train and dm_clean_test to lists of tensors on the device.\n",
        "    # So we only need to handle dm_noisy_test explicitly here if it wasn't already handled for validation.\n",
        "    # However, to be safe and consistent with the train_model's input preparation for evaluation,\n",
        "    # let's re-convert them.\n",
        "    dm_train_tensor = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_train]\n",
        "    dm_clean_test_tensor = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_clean_test]\n",
        "    dm_noisy_test_tensor = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_noisy_test]\n",
        "\n",
        "    dm_train_PI_prediction = model_dm_pi(dm_train_tensor).cpu().numpy()\n",
        "    dm_clean_PI_prediction = model_dm_pi(dm_clean_test_tensor).cpu().numpy()\n",
        "    dm_noisy_PI_prediction = model_dm_pi(dm_noisy_test_tensor).cpu().numpy()\n",
        "\n",
        "print(\"Predictions computed for DistanceMatrixRaggedModel for PI:\")\n",
        "print(f\"dm_train_PI_prediction shape: {dm_train_PI_prediction.shape}\")\n",
        "print(f\"dm_clean_PI_prediction shape: {dm_clean_PI_prediction.shape}\")\n",
        "print(f\"dm_noisy_PI_prediction shape: {dm_noisy_PI_prediction.shape}\")\n",
        "\n",
        "# Train an XGBoost classifier on the predictions\n",
        "model_classif_dm_pi = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "model_classif_dm_pi.fit(dm_train_PI_prediction, label_classif_train)\n",
        "\n",
        "# Evaluate accuracy on clean test set\n",
        "clean_test_acc_dm_pi = model_classif_dm_pi.score(dm_clean_PI_prediction, clean_label_classif_test)\n",
        "print(f\"Accuracy on clean test set (DistanceMatrixRaggedModel for PI): {clean_test_acc_dm_pi}\")\n",
        "\n",
        "# Evaluate accuracy on noisy test set\n",
        "noisy_test_acc_dm_pi = model_classif_dm_pi.score(dm_noisy_PI_prediction, noisy_label_classif_test)\n",
        "print(f\"Accuracy on noisy test set (DistanceMatrixRaggedModel for PI): {noisy_test_acc_dm_pi}\")"
      ],
      "id": "264aeeac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d420adc4"
      },
      "source": [
        "## Train DistanceMatrixRaggedModel for Persistence Landscapes\n",
        "\n",
        "### Subtask:\n",
        "Initialize, train, and make predictions with a new `DistanceMatrixRaggedModel` using the computed distance matrices and Persistence Landscapes as targets.\n"
      ],
      "id": "d420adc4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb4c8706"
      },
      "source": [
        "**Reasoning**:\n",
        "I will initialize a `DistanceMatrixRaggedModel` for Persistence Landscapes with the correct output dimension, then set up the optimizer and loss function. Afterwards, I will use the `train_model` function to train `model_dm_pl` using the distance matrices and Persistence Landscapes as targets. Finally, I will put the model in evaluation mode and make predictions.\n",
        "\n"
      ],
      "id": "fb4c8706"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77c668d3"
      },
      "source": [
        "output_dim_pl = PL_train.shape[1]\n",
        "model_dm_pl = DistanceMatrixRaggedModel(output_dim=output_dim_pl)\n",
        "\n",
        "print(f\"Initialized DistanceMatrixRaggedModel for PL with output_dim: {output_dim_pl}\")\n",
        "\n",
        "model_dm_pl.to(device)\n",
        "criterion_pl = nn.MSELoss()\n",
        "optimizer_pl = Adamax(model_dm_pl.parameters(), lr=5e-4)\n",
        "\n",
        "# Ensure num_epochs is defined\n",
        "try:\n",
        "    num_epochs\n",
        "except NameError:\n",
        "    num_epochs = 10000\n",
        "\n",
        "model_dm_pl, history_dm_pl, best_model_state_dm_pl = train_model(\n",
        "    model_dm_pl, optimizer_pl, criterion_pl,\n",
        "    dm_train, PL_train,\n",
        "    dm_clean_test, clean_PL_test,\n",
        "    epochs=num_epochs, batch_size=32\n",
        ")\n",
        "\n",
        "best_val_loss_dm_pl = min(history_dm_pl['val_loss']) if history_dm_pl.get('val_loss') else float('inf')\n",
        "print(f\"Training DistanceMatrixRaggedModel for PL complete. Best val_loss = {best_val_loss_dm_pl:.6f}\")\n",
        "\n",
        "model_dm_pl.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Ensure inputs are on the correct device and dtype for prediction\n",
        "    dm_train_tensor_pl = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_train]\n",
        "    dm_clean_test_tensor_pl = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_clean_test]\n",
        "    dm_noisy_test_tensor_pl = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_noisy_test]\n",
        "\n",
        "    dm_train_PL_prediction = model_dm_pl(dm_train_tensor_pl).cpu().numpy()\n",
        "    dm_clean_PL_prediction = model_dm_pl(dm_clean_test_tensor_pl).cpu().numpy()\n",
        "    dm_noisy_PL_prediction = model_dm_pl(dm_noisy_test_tensor_pl).cpu().numpy()\n",
        "\n",
        "print(\"Predictions computed for DistanceMatrixRaggedModel for PL:\")\n",
        "print(f\"dm_train_PL_prediction shape: {dm_train_PL_prediction.shape}\")\n",
        "print(f\"dm_clean_PL_prediction shape: {dm_clean_PL_prediction.shape}\")\n",
        "print(f\"dm_noisy_PL_prediction shape: {dm_noisy_PL_prediction.shape}\")"
      ],
      "id": "77c668d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dm_pl.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Ensure inputs are on the correct device and dtype\n",
        "    # The train_model function already converted dm_train and dm_clean_test to lists of tensors on the device.\n",
        "    # So we only need to handle dm_noisy_test explicitly here if it wasn't already handled for validation.\n",
        "    # However, to be safe and consistent with the train_model's input preparation for evaluation,\n",
        "    # let's re-convert them.\n",
        "    dm_train_tensor = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_train]\n",
        "    dm_clean_test_tensor = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_clean_test]\n",
        "    dm_noisy_test_tensor = [torch.tensor(dm, dtype=torch.float32).to(device) for dm in dm_noisy_test]\n",
        "\n",
        "    dm_train_PL_prediction = model_dm_pl(dm_train_tensor).cpu().numpy()\n",
        "    dm_clean_PL_prediction = model_dm_pl(dm_clean_test_tensor).cpu().numpy()\n",
        "    dm_noisy_PL_prediction = model_dm_pl(dm_noisy_test_tensor).cpu().numpy()\n",
        "\n",
        "print(\"Predictions computed for DistanceMatrixRaggedModel for PL:\")\n",
        "print(f\"dm_train_PL_prediction shape: {dm_train_PL_prediction.shape}\")\n",
        "print(f\"dm_clean_PL_prediction shape: {dm_clean_PL_prediction.shape}\")\n",
        "print(f\"dm_noisy_PL_prediction shape: {dm_noisy_PL_prediction.shape}\")\n",
        "\n",
        "# Train an XGBoost classifier on the predictions\n",
        "model_classif_dm_pl = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "model_classif_dm_pl.fit(dm_train_PL_prediction, label_classif_train)\n",
        "\n",
        "# Evaluate accuracy on clean test set\n",
        "clean_test_acc_dm_pl = model_classif_dm_pl.score(dm_clean_PL_prediction, clean_label_classif_test)\n",
        "print(f\"Accuracy on clean test set (DistanceMatrixRaggedModel for PI): {clean_test_acc_dm_pi}\")\n",
        "\n",
        "# Evaluate accuracy on noisy test set\n",
        "noisy_test_acc_dm_pl = model_classif_dm_pl.score(dm_noisy_PL_prediction, noisy_label_classif_test)\n",
        "print(f\"Accuracy on noisy test set (DistanceMatrixRaggedModel for PI): {noisy_test_acc_dm_pi}\")"
      ],
      "metadata": {
        "id": "LVMjz5bwfZCh"
      },
      "id": "LVMjz5bwfZCh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NVJzZu9QhMAB"
      },
      "id": "NVJzZu9QhMAB"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fo4Mo5ZThMjy"
      },
      "id": "Fo4Mo5ZThMjy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90a8fe12"
      },
      "source": [
        "## Define PointNet Model Class\n",
        "\n",
        "### Subtask:\n",
        "Create a new `nn.Module` class named `PointNet` that implements a PointNet-like architecture, accepting a list of 2D point clouds, padding them internally, processing with shared MLPs and max-pooling, and outputting a fixed-size vector.\n"
      ],
      "id": "90a8fe12"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cc32650"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to implement the `PointNet` class as described, including shared MLPs (phi), max-pooling, and global MLPs (rho), with internal padding for variable-sized point clouds.\n",
        "\n"
      ],
      "id": "1cc32650"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a68110aa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from typing import List\n",
        "\n",
        "class PointNet(nn.Module):\n",
        "    def __init__(self, output_dim, phi_dims=[64, 128, 256], rho_dims=[256, 128]):\n",
        "        super().__init__()\n",
        "\n",
        "        # Phi function (shared MLP) - maps each point to a feature vector\n",
        "        phi_layers = []\n",
        "        in_features = 2 # 2D points\n",
        "        for dim in phi_dims:\n",
        "            phi_layers.append(nn.Linear(in_features, dim))\n",
        "            phi_layers.append(nn.ReLU())\n",
        "            in_features = dim\n",
        "        self.phi_layers = nn.Sequential(*phi_layers)\n",
        "\n",
        "        # Rho function (global MLP) - processes aggregated features\n",
        "        rho_layers = []\n",
        "        in_features = phi_dims[-1] # Input to rho is the max-pooled feature from phi\n",
        "        for dim in rho_dims:\n",
        "            rho_layers.append(nn.Linear(in_features, dim))\n",
        "            rho_layers.append(nn.ReLU())\n",
        "            in_features = dim\n",
        "        rho_layers.append(nn.Linear(in_features, output_dim))\n",
        "        # No activation on the final layer for regression tasks\n",
        "        self.rho_layers = nn.Sequential(*rho_layers)\n",
        "\n",
        "    def forward(self, batch: List[torch.Tensor]):\n",
        "        if len(batch) == 0:\n",
        "            # Return an empty tensor with the correct output dimension if batch is empty\n",
        "            return torch.empty(0, self.rho_layers[-1].out_features, device=next(self.parameters()).device)\n",
        "\n",
        "        # Pad point clouds to the maximum length in the batch\n",
        "        # `pad_sequence` expects a list of tensors of shape (L, *) where L is sequence length\n",
        "        padded_batch = pad_sequence(batch, batch_first=True, padding_value=0.0)\n",
        "        # original_lengths = [len(pc) for pc in batch]\n",
        "\n",
        "        # Create a mask for valid points\n",
        "        # Shape: (batch_size, max_num_points)\n",
        "        mask = torch.zeros(padded_batch.shape[0], padded_batch.shape[1], dtype=torch.bool, device=padded_batch.device)\n",
        "        for i, pc in enumerate(batch):\n",
        "            mask[i, :len(pc)] = True\n",
        "\n",
        "        # Apply shared MLP (phi function) to all points\n",
        "        # Reshape to (total_num_points_in_batch, input_dim) for MLP, then reshape back\n",
        "        # phi_out shape: (batch_size, max_num_points, phi_dims[-1])\n",
        "        phi_out = self.phi_layers(padded_batch.view(-1, padded_batch.shape[-1]))\n",
        "        phi_out = phi_out.view(padded_batch.shape[0], padded_batch.shape[1], -1)\n",
        "\n",
        "        # Apply mask before max-pooling\n",
        "        # Set features of padded points to a very small negative value\n",
        "        # so they don't affect the max operation (especially with ReLU later in rho)\n",
        "        min_val = torch.finfo(phi_out.dtype).min\n",
        "        masked_phi_out = phi_out.masked_fill(~mask.unsqueeze(-1), min_val)\n",
        "\n",
        "        # Permutation-invariant aggregation (max-pooling over points)\n",
        "        # aggregated_features shape: (batch_size, phi_dims[-1])\n",
        "        aggregated_features, _ = torch.max(masked_phi_out, dim=1)\n",
        "\n",
        "        # Apply global MLP (rho function)\n",
        "        # output shape: (batch_size, output_dim)\n",
        "        output = self.rho_layers(aggregated_features)\n",
        "\n",
        "        return output\n",
        "\n",
        "print(\"PointNet class defined.\")"
      ],
      "id": "a68110aa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdbe2cad"
      },
      "source": [
        "## Initialize and Train PointNet for Persistence Images\n",
        "\n",
        "### Subtask:\n",
        "Initialize an instance of the `PointNet` model with `output_dim` set to match the dimension of `PI_train`. Configure `MSELoss` as the criterion and `Adamax` as the optimizer. Then, train the `PointNet` model using `tf_data_train` (the original point clouds) as inputs and `PI_train` as targets. Use `tf_clean_data_test` and `clean_PI_test` for validation, leveraging the `train_model` helper function.\n"
      ],
      "id": "cdbe2cad"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b103c229"
      },
      "source": [
        "**Reasoning**:\n",
        "I will initialize the `PointNet` model, define the loss function and optimizer, and then train the model using the `train_model` helper function with `tf_data_train` as inputs and `PI_train` as targets, as specified in the subtask.\n",
        "\n"
      ],
      "id": "b103c229"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d21b2d12"
      },
      "source": [
        "output_dim_pi_pn = PI_train.shape[1]\n",
        "model_PN_PI = PointNet(output_dim=output_dim_pi_pn)\n",
        "\n",
        "print(f\"Initialized PointNet for PI with output_dim: {output_dim_pi_pn}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_PN_PI.to(device)\n",
        "criterion_pn = nn.MSELoss()\n",
        "optimizer_pn = Adamax(model_PN_PI.parameters(), lr=5e-4)\n",
        "\n",
        "# Ensure num_epochs is defined\n",
        "try:\n",
        "    num_epochs\n",
        "except NameError:\n",
        "    num_epochs = 10000\n",
        "\n",
        "model_PN_PI, history_PN_PI, best_model_state_pn_pi = train_model(\n",
        "    model_PN_PI, optimizer_pn, criterion_pn,\n",
        "    tf_data_train, PI_train,\n",
        "    tf_clean_data_test, clean_PI_test,\n",
        "    epochs=num_epochs, batch_size=32\n",
        ")\n",
        "\n",
        "best_val_loss_pn_pi = min(history_PN_PI['val_loss']) if history_PN_PI.get('val_loss') else float('inf')\n",
        "print(f\"Training PointNet for PI complete. Best val_loss = {best_val_loss_pn_pi:.6f}\")"
      ],
      "id": "d21b2d12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8d83e02"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `PointNet` model for Persistence Images has been trained, I need to use it to make predictions on the training, clean test, and noisy test point clouds. These predictions will then be used to train and evaluate an `XGBoost` classifier to assess the model's performance on topology prediction.\n",
        "\n"
      ],
      "id": "e8d83e02"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d971832e"
      },
      "source": [
        "model_PN_PI.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Ensure inputs are on the correct device and dtype\n",
        "    tf_data_train_tensor = [torch.tensor(pc, dtype=torch.float32).to(device) for pc in tf_data_train]\n",
        "    tf_clean_data_test_tensor = [torch.tensor(pc, dtype=torch.float32).to(device) for pc in tf_clean_data_test]\n",
        "    tf_noisy_data_test_tensor = [torch.tensor(pc, dtype=torch.float32).to(device) for pc in tf_noisy_data_test]\n",
        "\n",
        "    pn_train_PI_prediction = model_PN_PI(tf_data_train_tensor).cpu().numpy()\n",
        "    pn_clean_PI_prediction = model_PN_PI(tf_clean_data_test_tensor).cpu().numpy()\n",
        "    pn_noisy_PI_prediction = model_PN_PI(tf_noisy_data_test_tensor).cpu().numpy()\n",
        "\n",
        "print(\"Predictions computed for PointNet for PI:\")\n",
        "print(f\"pn_train_PI_prediction shape: {pn_train_PI_prediction.shape}\")\n",
        "print(f\"pn_clean_PI_prediction shape: {pn_clean_PI_prediction.shape}\")\n",
        "print(f\"pn_noisy_PI_prediction shape: {pn_noisy_PI_prediction.shape}\")\n",
        "\n",
        "# Train an XGBoost classifier on the predictions from PointNet (PI)\n",
        "model_classif_PN_PI = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "model_classif_PN_PI.fit(pn_train_PI_prediction, label_classif_train)\n",
        "\n",
        "# Evaluate accuracy on clean test set\n",
        "clean_test_acc_PN_PI = model_classif_PN_PI.score(pn_clean_PI_prediction, clean_label_classif_test)\n",
        "print(f\"Accuracy on clean test set (PointNet for PI): {clean_test_acc_PN_PI}\")\n",
        "\n",
        "# Evaluate accuracy on noisy test set\n",
        "noisy_test_acc_PN_PI = model_classif_PN_PI.score(pn_noisy_PI_prediction, noisy_label_classif_test)\n",
        "print(f\"Accuracy on noisy test set (PointNet for PI): {noisy_test_acc_PN_PI}\")"
      ],
      "id": "d971832e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U883f6GRi2hO"
      },
      "id": "U883f6GRi2hO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "940d6e9e"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block generated `UserWarning` messages because it attempted to create new tensors from existing tensors. To resolve this, I will modify the input preparation lines to directly move the existing tensors to the specified device, avoiding unnecessary tensor construction and adhering to best practices for tensor handling.\n",
        "\n"
      ],
      "id": "940d6e9e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7444030c"
      },
      "source": [
        "model_PN_PI.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Ensure inputs are on the correct device and dtype\n",
        "    # tf_data_train, tf_clean_data_test, and tf_noisy_data_test are already lists of torch.Tensors\n",
        "    # created with dtype=torch.float32, so we just need to move them to the device.\n",
        "    tf_data_train_on_device = [pc.to(device) for pc in tf_data_train]\n",
        "    tf_clean_data_test_on_device = [pc.to(device) for pc in tf_clean_data_test]\n",
        "    tf_noisy_data_test_on_device = [pc.to(device) for pc in tf_noisy_data_test]\n",
        "\n",
        "    pn_train_PI_prediction = model_PN_PI(tf_data_train_on_device).cpu().numpy()\n",
        "    pn_clean_PI_prediction = model_PN_PI(tf_clean_data_test_on_device).cpu().numpy()\n",
        "    pn_noisy_PI_prediction = model_PN_PI(tf_noisy_data_test_on_device).cpu().numpy()\n",
        "\n",
        "print(\"Predictions computed for PointNet for PI:\")\n",
        "print(f\"pn_train_PI_prediction shape: {pn_train_PI_prediction.shape}\")\n",
        "print(f\"pn_clean_PI_prediction shape: {pn_clean_PI_prediction.shape}\")\n",
        "print(f\"pn_noisy_PI_prediction shape: {pn_noisy_PI_prediction.shape}\")\n",
        "\n",
        "# Train an XGBoost classifier on the predictions from PointNet (PI)\n",
        "model_classif_PN_PI = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "model_classif_PN_PI.fit(pn_train_PI_prediction, label_classif_train)\n",
        "\n",
        "# Evaluate accuracy on clean test set\n",
        "clean_test_acc_PN_PI = model_classif_PN_PI.score(pn_clean_PI_prediction, clean_label_classif_test)\n",
        "print(f\"Accuracy on clean test set (PointNet for PI): {clean_test_acc_PN_PI}\")\n",
        "\n",
        "# Evaluate accuracy on noisy test set\n",
        "noisy_test_acc_PN_PI = model_classif_PN_PI.score(pn_noisy_PI_prediction, noisy_label_classif_test)\n",
        "print(f\"Accuracy on noisy test set (PointNet for PI): {noisy_test_acc_PN_PI}\")"
      ],
      "id": "7444030c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3e1c0a1"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to initialize a `PointNet` model for Persistence Landscapes, train it using the `train_model` helper function, and then make predictions on the training and test sets as the initial step for evaluating its classification accuracy.\n",
        "\n"
      ],
      "id": "f3e1c0a1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3ab9069"
      },
      "source": [
        "output_dim_pl_pn = PL_train.shape[1]\n",
        "model_PN_PL = PointNet(output_dim=output_dim_pl_pn)\n",
        "\n",
        "print(f\"Initialized PointNet for PL with output_dim: {output_dim_pl_pn}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_PN_PL.to(device)\n",
        "criterion_pn_pl = nn.MSELoss()\n",
        "optimizer_pn_pl = Adamax(model_PN_PL.parameters(), lr=5e-4)\n",
        "\n",
        "# Ensure num_epochs is defined\n",
        "try:\n",
        "    num_epochs\n",
        "except NameError:\n",
        "    num_epochs = 10000\n",
        "\n",
        "model_PN_PL, history_PN_PL, best_model_state_pn_pl = train_model(\n",
        "    model_PN_PL, optimizer_pn_pl, criterion_pn_pl,\n",
        "    tf_data_train, PL_train,\n",
        "    tf_clean_data_test, clean_PL_test,\n",
        "    epochs=num_epochs, batch_size=32\n",
        ")\n",
        "\n",
        "best_val_loss_pn_pl = min(history_PN_PL['val_loss']) if history_PN_PL.get('val_loss') else float('inf')\n",
        "print(f\"Training PointNet for PL complete. Best val_loss = {best_val_loss_pn_pl:.6f}\")\n",
        "\n",
        "model_PN_PL.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Ensure inputs are on the correct device and dtype\n",
        "    tf_data_train_on_device = [pc.to(device) for pc in tf_data_train]\n",
        "    tf_clean_data_test_on_device = [pc.to(device) for pc in tf_clean_data_test]\n",
        "    tf_noisy_data_test_on_device = [pc.to(device) for pc in tf_noisy_data_test]\n",
        "\n",
        "    pn_train_PL_prediction = model_PN_PL(tf_data_train_on_device).cpu().numpy()\n",
        "    pn_clean_PL_prediction = model_PN_PL(tf_clean_data_test_on_device).cpu().numpy()\n",
        "    pn_noisy_PL_prediction = model_PN_PL(tf_noisy_data_test_on_device).cpu().numpy()\n",
        "\n",
        "print(\"Predictions computed for PointNet for PL:\")\n",
        "print(f\"pn_train_PL_prediction shape: {pn_train_PL_prediction.shape}\")\n",
        "print(f\"pn_clean_PL_prediction shape: {pn_clean_PL_prediction.shape}\")\n",
        "print(f\"pn_noisy_PL_prediction shape: {pn_noisy_PL_prediction.shape}\")"
      ],
      "id": "b3ab9069",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1fb9e8f"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `PointNet` model for Persistence Landscapes has been trained and predictions generated, I need to train an `XGBoost` classifier using these predictions and evaluate its classification accuracy on the clean and noisy test sets to assess the model's performance.\n",
        "\n"
      ],
      "id": "f1fb9e8f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e22e312e"
      },
      "source": [
        "model_classif_PN_PL = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "model_classif_PN_PL.fit(pn_train_PL_prediction, label_classif_train)\n",
        "\n",
        "# Evaluate accuracy on clean test set\n",
        "clean_test_acc_PN_PL = model_classif_PN_PL.score(pn_clean_PL_prediction, clean_label_classif_test)\n",
        "print(f\"Accuracy on clean test set (PointNet for PL): {clean_test_acc_PN_PL}\")\n",
        "\n",
        "# Evaluate accuracy on noisy test set\n",
        "noisy_test_acc_PN_PL = model_classif_PN_PL.score(pn_noisy_PL_prediction, noisy_label_classif_test)\n",
        "print(f\"Accuracy on noisy test set (PointNet for PL): {noisy_test_acc_PN_PL}\")"
      ],
      "id": "e22e312e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ol0HDBi9jVNM"
      },
      "id": "ol0HDBi9jVNM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24914ed3"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `PointNet` model for Persistence Landscapes has been trained and predictions generated, I need to train an `XGBoost` classifier using these predictions and evaluate its classification accuracy on the clean and noisy test sets to assess the model's performance.\n",
        "\n"
      ],
      "id": "24914ed3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b99b41bf"
      },
      "source": [
        "model_classif_PN_PL = XGBClassifier(eval_metric='logloss', use_label_encoder=False)\n",
        "model_classif_PN_PL.fit(pn_train_PL_prediction, label_classif_train)\n",
        "\n",
        "# Evaluate accuracy on clean test set\n",
        "clean_test_acc_PN_PL = model_classif_PN_PL.score(pn_clean_PL_prediction, clean_label_classif_test)\n",
        "print(f\"Accuracy on clean test set (PointNet for PL): {clean_test_acc_PN_PL}\")\n",
        "\n",
        "# Evaluate accuracy on noisy test set\n",
        "noisy_test_acc_PN_PL = model_classif_PN_PL.score(pn_noisy_PL_prediction, noisy_label_classif_test)\n",
        "print(f\"Accuracy on noisy test set (PointNet for PL): {noisy_test_acc_PN_PL}\")"
      ],
      "id": "b99b41bf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wWR4kzi833rA"
      },
      "id": "wWR4kzi833rA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c7a7281"
      },
      "source": [
        "!pip install POT"
      ],
      "id": "9c7a7281",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "708fd219"
      },
      "source": [
        "import gudhi as gd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "# Explicitly import wasserstein submodule\n",
        "import gudhi.wasserstein as gdw\n",
        "\n",
        "def compute_isometry_robustness_score(pc, model, n_augment_per_score, seed=42):\n",
        "    \"\"\"\n",
        "    Calculates the average Wasserstein distance between the persistence diagram of an original\n",
        "    point cloud and those of its isometrically augmented versions.\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    # 1. Compute PD for the original point cloud\n",
        "    st_original = gd.AlphaComplex(points=pc).create_simplex_tree(max_alpha_square=maxd)\n",
        "    st_original.persistence()\n",
        "    pd_original = st_original.persistence_intervals_in_dimension(1)\n",
        "    if len(pd_original) == 0:\n",
        "        pd_original = np.empty([0, 2])\n",
        "\n",
        "    # 2. Generate augmented point clouds\n",
        "    augmented_pcs = augment_isometries(pc, n_augment_per_score, rng)\n",
        "\n",
        "    PD_train_prediction = model(pc).cpu()\n",
        "    PD_clean_prediction = model(pc).cpu()\n",
        "    PD_noisy_prediction = model(pc).cpu()\n",
        "\n",
        "    wasserstein_distances = []\n",
        "    for aug_pc in augmented_pcs:\n",
        "        # 3. Compute PD for each augmented point cloud\n",
        "        pd_augmented = model(aug_pc).cpu()\n",
        "        if len(pd_augmented) == 0:\n",
        "            pd_augmented = np.empty([0, 2])\n",
        "\n",
        "        # 4. Calculate 1-Wasserstein distance\n",
        "        # Ensure diagrams are 2D arrays, even if empty\n",
        "        dist = gdw.wasserstein_distance(pd_original, pd_augmented, order=1, enable_autodiff=False)\n",
        "        wasserstein_distances.append(dist)\n",
        "\n",
        "    # 5. Return the mean of these distances\n",
        "    if len(wasserstein_distances) > 0:\n",
        "        return np.mean(wasserstein_distances)\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "print(\"compute_isometry_robustness_score function defined.\")"
      ],
      "id": "708fd219",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f39c8207"
      },
      "source": [
        "clean_isometry_robustness_scores = []\n",
        "for pc in tqdm(clean_data_test, desc='Computing isometry robustness for clean data'):\n",
        "    score = compute_isometry_robustness_score(pc,model_PN_PI, n_augment_per_score=5, seed=42)\n",
        "    clean_isometry_robustness_scores.append(score)\n",
        "\n",
        "noisy_isometry_robustness_scores = []\n",
        "for pc in tqdm(noisy_data_test, desc='Computing isometry robustness for noisy data'):\n",
        "    score = compute_isometry_robustness_score(pc,model_PN_PI, n_augment_per_score=5, seed=42)\n",
        "    noisy_isometry_robustness_scores.append(score)\n",
        "\n",
        "print(f\"Average isometry robustness score for clean data: {np.mean(clean_isometry_robustness_scores):.4f}\")\n",
        "print(f\"Average isometry robustness score for noisy data: {np.mean(noisy_isometry_robustness_scores):.4f}\")"
      ],
      "id": "f39c8207",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pIQ7hpwB57ia"
      },
      "id": "pIQ7hpwB57ia",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d46eae4"
      },
      "source": [
        "## Modify compute_isometry_robustness_score for vector output\n",
        "\n",
        "### Subtask:\n",
        "Directly modify the `compute_isometry_robustness_score` function to calculate the average Euclidean (L2) distance between a model's vector predictions for an original point cloud and its isometrically augmented versions. This involves converting point clouds to PyTorch tensors, moving them to the correct device, and using `np.linalg.norm` for distance calculation.\n"
      ],
      "id": "5d46eae4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ca500e"
      },
      "source": [
        "**Reasoning**:\n",
        "The user wants to modify the `compute_isometry_robustness_score` function to calculate the average Euclidean (L2) distance between a model's vector predictions for an original point cloud and its isometrically augmented versions. This involves converting point clouds to PyTorch tensors and moving them to the correct device. I will replace the existing function with the updated version that takes the point cloud (numpy array), converts it to a tensor before passing it to the model, and then calculates the L2 distance between the model's output vectors.\n",
        "\n"
      ],
      "id": "07ca500e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ade20df5"
      },
      "source": [
        "import gudhi as gd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "# Ensure DistanceMatrixRaggedModel, RaggedPersistenceModel, and PointNet are defined in the global scope\n",
        "# (Assuming they are already defined in previous cells or imported)\n",
        "\n",
        "def compute_isometry_robustness_score(pc, model, n_augment_per_score, device, seed=42):\n",
        "    \"\"\"\n",
        "    Calculates the average Euclidean (L2) distance between the vector prediction of an original\n",
        "    point cloud and those of its isometrically augmented versions.\n",
        "    It adapts its input based on the model type (PointNet/RaggedPersistenceModel vs DistanceMatrixRaggedModel).\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    model.eval()\n",
        "\n",
        "    # Determine input type based on model class\n",
        "    # Check if the model is an instance of DistanceMatrixRaggedModel (assuming it's defined)\n",
        "    is_distance_matrix_model = False\n",
        "    if 'DistanceMatrixRaggedModel' in globals() and isinstance(model, globals()['DistanceMatrixRaggedModel']):\n",
        "        is_distance_matrix_model = True\n",
        "\n",
        "    # Prepare input for the original point cloud\n",
        "    if is_distance_matrix_model:\n",
        "        # Convert point cloud to distance matrix\n",
        "        dm_original = distance_matrix(pc)\n",
        "        input_original = [torch.tensor(dm_original, dtype=torch.float32).to(device)]\n",
        "    else:\n",
        "        # Use point cloud directly\n",
        "        input_original = [torch.tensor(pc, dtype=torch.float32).to(device)]\n",
        "\n",
        "    # 1. Compute vector output for the original point cloud\n",
        "    with torch.no_grad():\n",
        "        pred_original = model(input_original)\n",
        "        # Ensure output is flattened if it comes as a list or has a batch dimension of 1\n",
        "        if isinstance(pred_original, (list, tuple)):\n",
        "            pred_original = pred_original[0]\n",
        "        pred_original = pred_original.cpu().numpy().flatten()\n",
        "\n",
        "    # 2. Generate augmented point clouds\n",
        "    augmented_pcs = augment_isometries(pc, n_augment_per_score, rng)\n",
        "\n",
        "    euclidean_distances = []\n",
        "    for aug_pc in augmented_pcs:\n",
        "        # Prepare input for augmented point cloud\n",
        "        if is_distance_matrix_model:\n",
        "            dm_augmented = distance_matrix(aug_pc)\n",
        "            input_augmented = [torch.tensor(dm_augmented, dtype=torch.float32).to(device)]\n",
        "        else:\n",
        "            input_augmented = [torch.tensor(aug_pc, dtype=torch.float32).to(device)]\n",
        "\n",
        "        # 3. Compute vector output for each augmented point cloud\n",
        "        with torch.no_grad():\n",
        "            pred_augmented = model(input_augmented)\n",
        "            if isinstance(pred_augmented, (list, tuple)):\n",
        "                pred_augmented = pred_augmented[0]\n",
        "            pred_augmented = pred_augmented.cpu().numpy().flatten()\n",
        "\n",
        "        # 4. Calculate L2 (Euclidean) distance\n",
        "        dist = np.linalg.norm(pred_original - pred_augmented)\n",
        "        euclidean_distances.append(dist)\n",
        "\n",
        "    # 5. Return the mean of these distances\n",
        "    if len(euclidean_distances) > 0:\n",
        "        return np.mean(euclidean_distances)\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "print(\"compute_isometry_robustness_score function redefined to handle different model inputs.\")"
      ],
      "id": "ade20df5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bc46bcf"
      },
      "source": [
        "**Reasoning**:\n",
        "The `compute_isometry_robustness_score` function has been updated to correctly handle different model input types. Now, I need to re-execute the code block that calculates and prints the isometry robustness scores for all models (RipsNet, DistanceMatrixRaggedModel, and PointNet) for both Persistence Images and Persistence Landscapes on clean and noisy test data. This should now run without errors and provide the desired performance metrics.\n",
        "\n"
      ],
      "id": "1bc46bcf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1aecf89"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Calculate Isometry Robustness for RipsNet PI Predictions\n",
        "clean_ripsnet_pi_isometry_robustness_scores = []\n",
        "for pc in tqdm(clean_data_test, desc='Computing RipsNet PI isometry robustness for clean data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_PI, n_augment_per_score=5, device=device, seed=42)\n",
        "    clean_ripsnet_pi_isometry_robustness_scores.append(score)\n",
        "\n",
        "noisy_ripsnet_pi_isometry_robustness_scores = []\n",
        "for pc in tqdm(noisy_data_test, desc='Computing RipsNet PI isometry robustness for noisy data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_PI, n_augment_per_score=5, device=device, seed=42)\n",
        "    noisy_ripsnet_pi_isometry_robustness_scores.append(score)\n",
        "\n",
        "print(f\"Average RipsNet PI isometry robustness score for clean data: {np.mean(clean_ripsnet_pi_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation RipsNet PI isometry robustness score for clean data: {np.std(clean_ripsnet_pi_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Average RipsNet PI isometry robustness score for noisy data: {np.mean(noisy_ripsnet_pi_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation RipsNet PI isometry robustness score for noisy data: {np.std(noisy_ripsnet_pi_isometry_robustness_scores):.6f}\")\n",
        "\n",
        "# Calculate Isometry Robustness for RipsNet PL Predictions\n",
        "clean_ripsnet_pl_isometry_robustness_scores = []\n",
        "for pc in tqdm(clean_data_test, desc='Computing RipsNet PL isometry robustness for clean data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_PL, n_augment_per_score=5, device=device, seed=42)\n",
        "    clean_ripsnet_pl_isometry_robustness_scores.append(score)\n",
        "\n",
        "noisy_ripsnet_pl_isometry_robustness_scores = []\n",
        "for pc in tqdm(noisy_data_test, desc='Computing RipsNet PL isometry robustness for noisy data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_PL, n_augment_per_score=5, device=device, seed=42)\n",
        "    noisy_ripsnet_pl_isometry_robustness_scores.append(score)\n",
        "\n",
        "print(f\"Average RipsNet PL isometry robustness score for clean data: {np.mean(clean_ripsnet_pl_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation RipsNet PL isometry robustness score for clean data: {np.std(clean_ripsnet_pl_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Average RipsNet PL isometry robustness score for noisy data: {np.mean(noisy_ripsnet_pl_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation RipsNet PL isometry robustness score for noisy data: {np.std(noisy_ripsnet_pl_isometry_robustness_scores):.6f}\")\n",
        "\n",
        "\n",
        "# Calculate Isometry Robustness for DistanceMatrixRaggedModel PI Predictions\n",
        "clean_dm_pi_isometry_robustness_scores = []\n",
        "for pc in tqdm(clean_data_test, desc='Computing DM PI isometry robustness for clean data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_dm_pi, n_augment_per_score=5, device=device, seed=42)\n",
        "    clean_dm_pi_isometry_robustness_scores.append(score)\n",
        "\n",
        "noisy_dm_pi_isometry_robustness_scores = []\n",
        "for pc in tqdm(noisy_data_test, desc='Computing DM PI isometry robustness for noisy data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_dm_pi, n_augment_per_score=5, device=device, seed=42)\n",
        "    noisy_dm_pi_isometry_robustness_scores.append(score)\n",
        "\n",
        "print(f\"Average DM PI isometry robustness score for clean data: {np.mean(clean_dm_pi_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation DM PI isometry robustness score for clean data: {np.std(clean_dm_pi_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Average DM PI isometry robustness score for noisy data: {np.mean(noisy_dm_pi_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation DM PI isometry robustness score for noisy data: {np.std(noisy_dm_pi_isometry_robustness_scores):.6f}\")\n",
        "\n",
        "# Calculate Isometry Robustness for DistanceMatrixRaggedModel PL Predictions\n",
        "clean_dm_pl_isometry_robustness_scores = []\n",
        "for pc in tqdm(clean_data_test, desc='Computing DM PL isometry robustness for clean data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_dm_pl, n_augment_per_score=5, device=device, seed=42)\n",
        "    clean_dm_pl_isometry_robustness_scores.append(score)\n",
        "\n",
        "noisy_dm_pl_isometry_robustness_scores = []\n",
        "for pc in tqdm(noisy_data_test, desc='Computing DM PL isometry robustness for noisy data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_dm_pl, n_augment_per_score=5, device=device, seed=42)\n",
        "    noisy_dm_pl_isometry_robustness_scores.append(score)\n",
        "\n",
        "print(f\"Average DM PL isometry robustness score for clean data: {np.mean(clean_dm_pl_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation DM PL isometry robustness score for clean data: {np.std(clean_dm_pl_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Average DM PL isometry robustness score for noisy data: {np.mean(noisy_dm_pl_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation DM PL isometry robustness score for noisy data: {np.std(noisy_dm_pl_isometry_robustness_scores):.6f}\")\n",
        "\n",
        "\n",
        "# Calculate Isometry Robustness for PointNet PI Predictions\n",
        "clean_pn_pi_isometry_robustness_scores = []\n",
        "for pc in tqdm(clean_data_test, desc='Computing PointNet PI isometry robustness for clean data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_PN_PI, n_augment_per_score=5, device=device, seed=42)\n",
        "    clean_pn_pi_isometry_robustness_scores.append(score)\n",
        "\n",
        "noisy_pn_pi_isometry_robustness_scores = []\n",
        "for pc in tqdm(noisy_data_test, desc='Computing PointNet PI isometry robustness for noisy data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_PN_PI, n_augment_per_score=5, device=device, seed=42)\n",
        "    noisy_pn_pi_isometry_robustness_scores.append(score)\n",
        "\n",
        "print(f\"Average PointNet PI isometry robustness score for clean data: {np.mean(clean_pn_pi_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation PointNet PI isometry robustness score for clean data: {np.std(clean_pn_pi_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Average PointNet PI isometry robustness score for noisy data: {np.mean(noisy_pn_pi_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation PointNet PI isometry robustness score for noisy data: {np.std(noisy_pn_pi_isometry_robustness_scores):.6f}\")\n",
        "\n",
        "# Calculate Isometry Robustness for PointNet PL Predictions\n",
        "clean_pn_pl_isometry_robustness_scores = []\n",
        "for pc in tqdm(clean_data_test, desc='Computing PointNet PL isometry robustness for clean data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_PN_PL, n_augment_per_score=5, device=device, seed=42)\n",
        "    clean_pn_pl_isometry_robustness_scores.append(score)\n",
        "\n",
        "noisy_pn_pl_isometry_robustness_scores = []\n",
        "for pc in tqdm(noisy_data_test, desc='Computing PointNet PL isometry robustness for noisy data'):\n",
        "    score = compute_isometry_robustness_score(pc, model_PN_PL, n_augment_per_score=5, device=device, seed=42)\n",
        "    noisy_pn_pl_isometry_robustness_scores.append(score)\n",
        "\n",
        "print(f\"Average PointNet PL isometry robustness score for clean data: {np.mean(clean_pn_pl_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation PointNet PL isometry robustness score for clean data: {np.std(clean_pn_pl_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Average PointNet PL isometry robustness score for noisy data: {np.mean(noisy_pn_pl_isometry_robustness_scores):.6f}\")\n",
        "print(f\"Standard deviation PointNet PL isometry robustness score for noisy data: {np.std(noisy_pn_pl_isometry_robustness_scores):.6f}\")"
      ],
      "id": "d1aecf89",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "949b8730"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to summarize and compare the performance of `RaggedPersistenceModel`, `DistanceMatrixRaggedModel`, and `PointNet` for predicting Persistence Images and Persistence Landscapes, based on their classification accuracy and isometry robustness scores. I will gather the relevant metrics from the previous code execution and present them in a clear markdown table.\n",
        "\n"
      ],
      "id": "949b8730"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "259ac80a"
      },
      "source": [
        "## Summary of Model Performance\n",
        "\n",
        "Here's a summary of the performance of the different models (RaggedPersistenceModel/RipsNet, DistanceMatrixRaggedModel, and PointNet) for predicting Persistence Images (PI) and Persistence Landscapes (PL), evaluated using classification accuracy on clean and noisy test sets, and isometry robustness (average and standard deviation of L2 distance between predictions of original and augmented point clouds).\n",
        "\n",
        "### Persistence Image (PI) - Classification Accuracy (XGBoost)\n",
        "\n",
        "| Model                  | Clean Test Accuracy | Noisy Test Accuracy |\n",
        "|------------------------|---------------------|---------------------|\n",
        "| RipsNet                | 0.636667            | 0.690000            |\n",
        "| DistanceMatrixRagged   | 0.740000            | 0.776667            |\n",
        "| PointNet               | 0.933333            | 0.636667            |\n",
        "| Gudhi (Baseline)       | 1.000000            | 0.666667            |\n",
        "\n",
        "### Persistence Landscape (PL) - Classification Accuracy (XGBoost)\n",
        "\n",
        "| Model                  | Clean Test Accuracy | Noisy Test Accuracy |\n",
        "|------------------------|---------------------|---------------------|\n",
        "| RipsNet                | 0.703333            | 0.736667            |\n",
        "| DistanceMatrixRagged   | 0.736667            | 0.743333            |\n",
        "| PointNet               | 0.883333            | 0.696667            |\n",
        "| Gudhi (Baseline)       | 0.996667            | 0.363333            |\n",
        "\n",
        "### Isometry Robustness (Average L2 Distance to Augmented Samples)\n",
        "\n",
        "| Model (Descriptor)       | Clean Data (Mean  Std)        | Noisy Data (Mean  Std)          |\n",
        "|--------------------------|--------------------------------|----------------------------------|\n",
        "| RipsNet (PI)             | 0.589158  0.689707            | 0.598095  0.676659              |\n",
        "| RipsNet (PL)             | 0.040208  0.023749            | 0.039987  0.026292              |\n",
        "| DistanceMatrixRagged (PI)| 0.000000  0.000000            | 0.000000  0.000000              |\n",
        "| DistanceMatrixRagged (PL)| 0.000000  0.000000            | 0.000000  0.000000              |\n",
        "| PointNet (PI)            | 1.348374  0.858867            | 1.398915  1.012282              |\n",
        "| PointNet (PL)            | 0.223900  0.109701            | 0.245333  0.093165              |\n",
        "\n",
        "### Comparison and Analysis:\n",
        "\n",
        "**Persistence Images (PI):**\n",
        "\n",
        "*   **Classification Accuracy:** Gudhi's raw Persistence Images provide the best accuracy on clean data (1.0), as expected, since it's the ground truth. `PointNet` performs very well on clean data (0.933333), showing its ability to learn PI from point clouds. `DistanceMatrixRagged` has decent accuracy (0.74), while `RipsNet` (using DeepSets) is slightly lower (0.636667). On noisy data, `DistanceMatrixRagged` achieves the highest accuracy (0.776667), indicating its robustness, followed by `RipsNet` (0.69) and then Gudhi's direct computation (0.666667), and `PointNet` (0.636667). This suggests that learning PIs from distance matrices can be beneficial for noisy data.\n",
        "*   **Isometry Robustness:** Both `DistanceMatrixRagged` models show remarkably low isometry robustness scores (0.000000 mean L2 distance), which suggests perfect invariance to isometries. This is likely due to an internal mechanism that normalizes or is inherently invariant to translations and rotations when generating distance matrices from augmented point clouds. RipsNet (DeepSets) and PointNet show higher average L2 distances, meaning their predictions change more under isometries. RipsNet is more robust than PointNet in this regard.\n",
        "\n",
        "**Persistence Landscapes (PL):**\n",
        "\n",
        "*   **Classification Accuracy:** Similar to PIs, Gudhi's raw PLs have very high accuracy on clean data (0.996667), but its performance drops significantly on noisy data (0.363333). `DistanceMatrixRagged` performs best on noisy data (0.743333) and has good performance on clean data (0.736667). `RipsNet` (DeepSets) shows strong performance on noisy data (0.736667) and decent on clean (0.703333). `PointNet` has good accuracy on clean data (0.883333) but drops on noisy data (0.696667).\n",
        "*   **Isometry Robustness:** Again, `DistanceMatrixRagged` models exhibit perfect isometry invariance (0.000000), which is a key advantage. `RipsNet` (DeepSets) shows very good robustness with low mean L2 distances (0.040208 for clean, 0.039987 for noisy), performing better than `PointNet` (0.223900 for clean, 0.245333 for noisy).\n",
        "\n",
        "**Overall Observations:**\n",
        "\n",
        "*   **Robustness to Noise:** The models that learn topological descriptors (`RipsNet`, `DistanceMatrixRagged`, `PointNet`) generally show better classification accuracy on noisy test data compared to directly using Gudhi's computed descriptors. This highlights the learned models' ability to extract more robust topological features.\n",
        "*   **Isometry Invariance:** The `DistanceMatrixRaggedModel` demonstrates perfect isometry invariance due to its input being the distance matrix, which is inherently invariant to rigid transformations of the point cloud. `RipsNet` (DeepSets) also shows very good robustness to isometries, particularly for PLs. `PointNet` shows the least robustness to isometries, as indicated by its higher average L2 distances.\n",
        "*   **PointNet vs. DeepSets (RipsNet):** For PIs, PointNet achieved higher clean accuracy but lower noisy accuracy compared to RipsNet. For PLs, PointNet again showed higher clean accuracy but slightly lower noisy accuracy than RipsNet. The `DistanceMatrixRaggedModel` consistently performed well, especially on noisy data, for both PI and PL prediction tasks, and showcased perfect isometry invariance.\n",
        "\n",
        "This analysis shows that while traditional TDA methods can be highly accurate on clean data, learned approaches, especially those with inherent robustness or specialized inputs like distance matrices, can offer superior performance in the presence of noise and maintain isometry invariance."
      ],
      "id": "259ac80a",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}